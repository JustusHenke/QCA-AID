# QCA-AID Nutzerhandbuch
## Qualitative Inhaltsanalyse mit KI-Unterst√ºtzung

![QCA-AID Banner](banner-qca-aid.png)

**Version:** 0.11.1  
**Zielgruppe:** Sozialwissenschaftler:innen mit Erfahrung in qualitativer Forschung  
**Autor:** Justus Henke, Institut f√ºr Hochschulforschung Halle-Wittenberg

---

## Inhaltsverzeichnis

1. [Einf√ºhrung und Grundlagen](#1-einf√ºhrung-und-grundlagen)
2. [Design-Prinzipien von QCA-AID](#2-design-prinzipien-von-qca-aid)
3. [Die vier Kodiermodi](#3-die-vier-kodiermodi)
4. [Rolle der KI in QCA-AID](#4-rolle-der-ki-in-qca-aid)
5. [Installation und Einrichtung](#5-installation-und-einrichtung)
6. [LLM-Anbieter und Modellauswahl](#6-llm-anbieter-und-modellauswahl)
7. [Konfigurationseinstellungen](#7-konfigurationseinstellungen)
8. [Codebook-Entwicklung und -Pflege](#8-codebook-entwicklung-und-pflege)
9. [Arbeiten mit der Webapp](#9-arbeiten-mit-der-webapp)
10. [Output-Sheets und Ergebnisinterpretation](#10-output-sheets-und-ergebnisinterpretation)
11. [Optimaler Kodiermodus nach Forschungszielen](#11-optimaler-kodiermodus-nach-forschungszielen)
12. [Best Practices und Qualit√§tssicherung](#12-best-practices-und-qualit√§tssicherung)
13. [H√§ufige Probleme und L√∂sungen](#13-h√§ufige-probleme-und-l√∂sungen)
14. [Anhang: Screenshots und Beispiele](#14-anhang-screenshots-und-beispiele)

---

## 1. Einf√ºhrung und Grundlagen

### Was ist QCA-AID?

QCA-AID (Qualitative Content Analysis with AI-supported Discovery) ist ein innovatives Tool, das Mayrings Methode der deduktiven qualitativen Inhaltsanalyse mit induktiver Erweiterung durch KI-Unterst√ºtzung implementiert. Es kombiniert bew√§hrte qualitative Forschungsmethoden mit modernen KI-F√§higkeiten.

**Wichtiger Hinweis:** QCA-AID ersetzt nicht die menschliche Analyse, sondern erweitert die M√∂glichkeiten f√ºr strukturierte Textanalysen und schafft mehr Zeit f√ºr Reflexion und Interpretation.

### Anwendungsm√∂glichkeiten

- **Skalierung:** Analyse gr√∂√üerer Dokumentenmengen als in herk√∂mmlichen Verfahren
- **Qualit√§tssicherung:** Intercoder-Vergleiche mit KI-Codern zus√§tzlich zu menschlichen Codierern
- **Exploration:** Zus√§tzliche explorative Analysen ohne KI-Coder m√∂glich
- **Effizienz:** Alternative zu kostenpflichtigen QDA-Programmen

### Grenzen und Risiken

- **√úberkonfidenz:** Gefahr der unkritischen √úbernahme automatisiert ermittelter Strukturen
- **Dokumentenanzahl:** Bei wenigen Dokumenten √ºberwiegen Vorteile manueller Kodierung
- **Qualit√§tskontrolle:** Ergebnisse m√ºssen stets manuell validiert werden

---

## 2. Design-Prinzipien von QCA-AID

### Methodische Fundierung

QCA-AID basiert auf etablierten Prinzipien der qualitativen Inhaltsanalyse:

1. **Regelgeleitetheit:** Systematische Anwendung expliziter Kodierregeln
2. **Theoriegeleitetheit:** Deduktive Kategorien basieren auf theoretischen Vorannahmen
3. **Induktive Offenheit:** M√∂glichkeit zur Erweiterung des Kategoriensystems
4. **Intersubjektivit√§t:** Nachvollziehbare und √ºberpr√ºfbare Kodierungen

### Technische Architektur

- **Modularer Aufbau:** Getrennte Komponenten f√ºr verschiedene Funktionen
- **Flexibilit√§t:** Unterst√ºtzung verschiedener LLM-Anbieter und Modelle
- **Skalierbarkeit:** Batch-Verarbeitung f√ºr gro√üe Datenmengen
- **Transparenz:** Vollst√§ndige Dokumentation aller Kodierentscheidungen

---

## 3. Die vier Kodiermodi

QCA-AID bietet vier verschiedene Analysemodi, die sich in ihrer Offenheit f√ºr neue Kategorien unterscheiden:

### 3.1 Deduktiver Modus (`deductive`)

**Prinzip:** Ausschlie√üliche Verwendung vordefinierter Kategorien

**Anwendung:**
- Theoriepr√ºfung mit feststehendem Kategoriensystem
- Replikationsstudien
- Standardisierte Inhaltsanalysen

**Vorteile:**
- H√∂chste Vergleichbarkeit
- Klare theoretische Fundierung
- Schnelle Verarbeitung

**Nachteile:**
- Keine neuen Erkenntnisse m√∂glich
- Gefahr des "√úbersehens" relevanter Aspekte

### 3.2 Abduktiver Modus (`abductive`)

**Prinzip:** Erweiterung nur auf Subkategorien-Ebene

**Anwendung:**
- Verfeinerung bestehender Theorien
- Detaillierung bekannter Ph√§nomene
- Explorative Vertiefung

**Vorteile:**
- Balance zwischen Struktur und Offenheit
- Theoretische Koh√§renz bleibt erhalten
- Moderate Komplexit√§t

**Nachteile:**
- Hauptkategorien bleiben fix
- Begrenzte theoretische Innovation

### 3.3 Induktiver Modus (`full`)

**Prinzip:** Vollst√§ndige Erweiterung um neue Haupt- und Subkategorien

**Anwendung:**
- Theorieentwicklung
- Exploration neuer Ph√§nomene
- Grounded Theory-Ans√§tze

**Vorteile:**
- Maximale Offenheit f√ºr Neues
- Theoretische Innovation m√∂glich
- Umfassende Datenerschlie√üung

**Nachteile:**
- Hohe Komplexit√§t
- Gefahr der √úberstrukturierung
- Aufwendige Nachbearbeitung

### 3.4 Grounded Theory Modus (`grounded`)

**Prinzip:** Schrittweise Sammlung von Subcodes mit sp√§terer Hauptkategoriengenerierung

**Anwendung:**
- Reine Grounded Theory-Studien
- Explorative Vorstudien
- Theorieentwicklung aus den Daten

**Vorteile:**
- Maximale Datenn√§he
- Emergente Theoriebildung
- Minimale Vorannahmen

**Nachteile:**
- Sehr zeitaufwendig
- Hohe analytische Anforderungen
- Unvorhersagbare Ergebnisse

---

## 4. Rolle der KI in QCA-AID

### KI als Kodierungsassistent

Die KI in QCA-AID fungiert als:

1. **Systematischer Kodierer:** Konsistente Anwendung von Kodierregeln
2. **Mustererkenner:** Identifikation wiederkehrender Themen
3. **Kategorienentwickler:** Vorschl√§ge f√ºr neue Kategorien (induktive Modi)
4. **Qualit√§tspr√ºfer:** Intercoder-Reliabilit√§t durch mehrere KI-Codierer

### Grenzen der KI-Kodierung

- **Kontextverst√§ndnis:** Begrenzt auf explizite Textinhalte
- **Kulturelles Wissen:** Keine impliziten kulturellen Codes
- **Kreativit√§t:** Keine echte theoretische Innovation
- **Subjektivit√§t:** Keine Ber√ºcksichtigung von Forscherperspektiven

### Qualit√§tssicherung

- **Mehrfachkodierung:** Verschiedene KI-Codierer mit unterschiedlichen Parametern
- **Konsensbildung:** Automatische Identifikation √ºbereinstimmender Kodierungen
- **Menschliche Kontrolle:** Manuelle √úberpr√ºfung und Korrektur m√∂glich
- **Transparenz:** Vollst√§ndige Dokumentation aller Entscheidungen

---
## 5. Installation und Einrichtung

### 5.1 Systemvoraussetzungen

**Hardware:**
- Mindestens 4 GB RAM (8 GB empfohlen)
- 2 GB freier Festplattenspeicher
- Internetverbindung (f√ºr Cloud-Modelle)

**Software:**
- **Python 3.10 oder 3.11** (WICHTIG: Nicht Python 3.13!)
- Windows 10/11, macOS 10.14+, oder Linux
- Moderner Webbrowser (f√ºr Webapp)

### 5.2 Schritt-f√ºr-Schritt Installation

#### Schritt 1: Python installieren

**‚ö†Ô∏è Wichtiger Hinweis:** Verwenden Sie Python 3.11 oder √§lter, da QCA-AID derzeit nicht mit Python 3.13 kompatibel ist!

1. Download von [python.org](https://www.python.org/downloads/release/python-3110/)
2. Installation mit "Add to PATH" aktivieren
3. √úberpr√ºfung: `python --version` in der Kommandozeile

#### Schritt 2: QCA-AID herunterladen

**Option A: Git (empfohlen)**
```bash
git clone https://github.com/JustusHenke/QCA-AID.git
cd QCA-AID
```

**Option B: ZIP-Download**
1. GitHub-Repository besuchen
2. "Code" ‚Üí "Download ZIP"
3. Entpacken und in Ordner wechseln

#### Schritt 3: Abh√§ngigkeiten installieren

```bash
# Alle Pakete installieren
pip install -r requirements.txt

# Deutsches Sprachmodell f√ºr spaCy
python -m spacy download de_core_news_sm
```

**Windows-spezifisch:** Falls Fehler auftreten, installieren Sie die Microsoft Visual C++ Build Tools:
- Download: [Visual Studio Build Tools](https://visualstudio.microsoft.com/de/visual-cpp-build-tools/)
- Aktivieren Sie "C++ Build Tools" inklusive MSVC und Windows SDK

#### Schritt 4: Installation testen

```bash
# Webapp starten (einfachster Test)
python QCA_AID_app/start_webapp.py

# Oder Kommandozeilen-Version
python QCA-AID.py
```

### 5.3 Erste Konfiguration

#### API-Schl√ºssel einrichten

Erstellen Sie eine `.env`-Datei im QCA-AID-Verzeichnis:

```bash
# OpenAI (empfohlen f√ºr Einsteiger)
OPENAI_API_KEY=sk-proj-...

# Anthropic (Claude)
ANTHROPIC_API_KEY=sk-ant-...

# Mistral
MISTRAL_API_KEY=...

# OpenRouter
OPENROUTER_API_KEY=sk-or-...
```

**Sicherheitshinweis:** F√ºgen Sie `.env` zu Ihrer `.gitignore` hinzu!

#### Verzeichnisstruktur erstellen

```
mein-projekt/
‚îú‚îÄ‚îÄ input/          # Ihre Textdateien (.txt, .pdf, .docx)
‚îú‚îÄ‚îÄ output/         # Analyseergebnisse
‚îú‚îÄ‚îÄ config/         # Konfigurationsdateien (optional)
‚îî‚îÄ‚îÄ codebooks/      # Codebook-Dateien (optional)
```

---

## 6. LLM-Anbieter und Modellauswahl

### 6.1 √úbersicht der Anbieter

| Anbieter | Datenschutz | Kosten | Qualit√§t | Einrichtung |
|----------|-------------|--------|----------|-------------|
| **Lokal** ‚≠ê | ‚úÖ 100% privat | ‚úÖ Kostenlos | ‚≠ê‚≠ê‚≠ê Gut | ‚≠ê‚≠ê Mittel |
| **OpenAI** | ‚ö†Ô∏è Cloud | üí∞üí∞ Moderat | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Exzellent | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Einfach |
| **Anthropic** | ‚ö†Ô∏è Cloud | üí∞üí∞üí∞ Hoch | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Exzellent | ‚≠ê‚≠ê‚≠ê‚≠ê Einfach |
| **Mistral** | ‚ö†Ô∏è Cloud | üí∞ G√ºnstig | ‚≠ê‚≠ê‚≠ê‚≠ê Sehr gut | ‚≠ê‚≠ê‚≠ê‚≠ê Einfach |

### 6.2 Lokale Modelle (Empfohlen f√ºr sensible Daten)

**Vorteile:**
- ‚úÖ **100% Datenschutz** - Keine Daten√ºbermittlung
- ‚úÖ **Kostenlos** - Keine API-Geb√ºhren
- ‚úÖ **DSGVO-konform** - Ideal f√ºr Forschungsdaten
- ‚úÖ **Offline-f√§hig** - Keine Internetverbindung n√∂tig

**Einrichtung mit LM Studio (Empfohlen f√ºr Einsteiger):**

1. **Download:** [lmstudio.ai](https://lmstudio.ai/)
2. **Modell herunterladen:**
   - "Discover" Tab √∂ffnen
   - Nach "Llama 3.1 8B" suchen
   - Download starten
3. **Server starten:**
   - "Local Server" Tab
   - Modell ausw√§hlen
   - "Start Server" (Port 1234)
4. **In QCA-AID verwenden:**
   - Webapp: "Local (LM Studio/Ollama)" w√§hlen
   - "üîÑ Erkennen" klicken
   - Modell ausw√§hlen

**Empfohlene lokale Modelle:**

| Modell | Gr√∂√üe | RAM-Bedarf | Geschwindigkeit | Qualit√§t |
|--------|-------|------------|-----------------|----------|
| **Llama 3.1 8B** | 4.7 GB | 8 GB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê |
| **Qwen 2.5 14B** | 8.5 GB | 16 GB | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Mistral 7B** | 4.1 GB | 8 GB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê |

### 6.3 Cloud-Modelle

**OpenAI (Empfohlen f√ºr h√∂chste Qualit√§t):**
- `gpt-4o-mini`: G√ºnstig, schnell, gute Qualit√§t
- `gpt-4o`: Teurer, beste Qualit√§t
- `gpt-4-turbo`: Balance aus Geschwindigkeit und Qualit√§t

**Anthropic (Claude):**
- `claude-3-5-sonnet`: Sehr gute Textanalyse
- `claude-3-opus`: H√∂chste Qualit√§t, teuer

**Mistral:**
- `mistral-large-latest`: Beste Mistral-Qualit√§t
- `mistral-small-latest`: G√ºnstig, ausreichend

### 6.4 Modellauswahl-Empfehlungen

**F√ºr Einsteiger:**
- Cloud: OpenAI `gpt-4o-mini`
- Lokal: Llama 3.1 8B

**F√ºr sensible Daten:**
- Nur lokale Modelle verwenden
- Qwen 2.5 14B (beste Qualit√§t)

**F√ºr gro√üe Projekte:**
- Cloud: OpenAI `gpt-4o` (beste Qualit√§t)
- Lokal: Llama 3.1 70B (falls genug RAM)

**F√ºr Budgetbeschr√§nkungen:**
- Cloud: Mistral `mistral-small-latest`
- Lokal: Mistral 7B

---

## 7. Konfigurationseinstellungen

### 7.1 Konfigurationsformate

QCA-AID unterst√ºtzt zwei Formate, die automatisch synchronisiert werden:

**Excel-Format (`QCA-AID-Codebook.xlsx`):**
- ‚úÖ Vertraute Oberfl√§che
- ‚úÖ Einfache Bearbeitung
- ‚ùå Langsamer beim Laden
- ‚ùå Schwieriger f√ºr Versionskontrolle

**JSON-Format (`QCA-AID-Codebook.json`):**
- ‚úÖ 10x schneller beim Laden
- ‚úÖ Ideal f√ºr Git-Versionskontrolle
- ‚úÖ Bessere Performance
- ‚ùå Erfordert JSON-Kenntnisse

### 7.2 Grundkonfiguration

#### Modell-Einstellungen

```json
{
  "config": {
    "MODEL_PROVIDER": "OpenAI",        // "OpenAI", "Anthropic", "Mistral", "local"
    "MODEL_NAME": "gpt-4o-mini",       // Spezifisches Modell
    "DATA_DIR": "input",               // Eingabeverzeichnis
    "OUTPUT_DIR": "output"             // Ausgabeverzeichnis
  }
}
```

#### Chunk-Einstellungen

```json
{
  "CHUNK_SIZE": 1000,        // Textabschnittsgr√∂√üe (800-1500 Z.)
  "CHUNK_OVERLAP": 50,       // √úberlappung zwischen Chunks (30-100 Z.)
  "BATCH_SIZE": 5            // Parallel verarbeitete Chunks (3-12)
}
```

**Empfehlungen nach Dokumenttyp:**

| Dokumenttyp | CHUNK_SIZE | CHUNK_OVERLAP | BATCH_SIZE |
|-------------|------------|---------------|------------|
| **Interviews** | 1000 | 50 | 5 |
| **Lange Texte** | 1500 | 100 | 4 |
| **Kurze Dokumente** | 800 | 30 | 8 |
| **Akademische Papers** | 1200 | 60 | 5 |

### 7.3 Erweiterte Einstellungen

#### Analysemodus-Konfiguration

```json
{
  "ANALYSIS_MODE": "deductive",      // "deductive", "abductive", "grounded"
  "CODE_WITH_CONTEXT": true,         // Kontextuelle Kodierung
  "MULTIPLE_CODINGS": true,          // Mehrfachkodierungen erlauben
  "MULTIPLE_CODING_THRESHOLD": 0.85  // Schwellwert f√ºr Mehrfachkodierung
}
```

#### Coder-Einstellungen

```json
{
  "CODER_SETTINGS": [
    {
      "temperature": 0.3,    // Konsistenz (0.0-1.0)
      "coder_id": "auto_1"   // Eindeutige ID
    },
    {
      "temperature": 0.5,    // Etwas kreativer
      "coder_id": "auto_2"
    }
  ]
}
```

**Temperature-Empfehlungen:**
- **0.0-0.3:** Sehr konsistent (deduktive Kodierung)
- **0.4-0.6:** Ausgewogen (abduktive Kodierung)
- **0.7-1.0:** Kreativ (induktive Kodierung)

#### Qualit√§tssicherung

```json
{
  "REVIEW_MODE": "consensus",        // "auto", "consensus", "majority", "manual"
  "AUTO_SAVE_INTERVAL": 10,          // Automatische Sicherung (Minuten)
  "MANUAL_CODING_ENABLED": false     // Manuelle Kodierung aktivieren
}
```

### 7.4 Attribut-Extraktion

QCA-AID kann Metadaten aus Dateinamen extrahieren:

```json
{
  "ATTRIBUTE_LABELS": {
    "attribut1": "Hochschultyp",
    "attribut2": "Position", 
    "attribut3": "Fachbereich"
  }
}
```

**Beispiel:**
- Dateiname: `Universit√§t_Professor_Informatik_Interview.txt`
- Extrahiert: Hochschultyp="Universit√§t", Position="Professor", Fachbereich="Informatik"

### 7.5 Performance-Optimierung

#### Batch-Gr√∂√üe anpassen

```json
{
  "BATCH_SIZE": 8  // Erh√∂hen f√ºr mehr Geschwindigkeit, reduzieren f√ºr mehr Pr√§zision
}
```

**Empfehlungen:**
- **Hohe Pr√§zision:** 3-4 (langsamer, genauer)
- **Standard:** 5-8 (ausgewogen)
- **Hohe Geschwindigkeit:** 10-12 (schneller, weniger pr√§zise)

#### Kontextuelle Kodierung

```json
{
  "CODE_WITH_CONTEXT": true  // Aktiviert progressive Dokumentzusammenfassung
}
```

**Vorteile:**
- Bessere Kontextsensitivit√§t
- Konsistentere Kodierung innerhalb von Dokumenten

**Nachteile:**
- Langsamere Verarbeitung
- H√∂herer Token-Verbrauch

---
## 8. Codebook-Entwicklung und -Pflege

### 8.1 Struktur eines QCA-AID Codebooks

Ein vollst√§ndiges Codebook besteht aus vier Hauptkomponenten:

#### Forschungsfrage
```json
{
  "forschungsfrage": "Wie gestaltet sich die digitale Transformation in deutschen Hochschulen und welche Herausforderungen und Chancen lassen sich dabei identifizieren?"
}
```

**Best Practices:**
- Formulieren Sie pr√§zise und fokussiert
- Vermeiden Sie zu breite oder zu enge Fragestellungen
- Die Frage sollte zum Kategoriensystem passen

#### Kodierregeln
```json
{
  "kodierregeln": {
    "general": [
      "Kodiere nur explizite Aussagen, keine Interpretationen",
      "Ber√ºcksichtige den Kontext der Aussage",
      "Bei Unsicherheit dokumentiere die Gr√ºnde"
    ],
    "format": [
      "Markiere relevante Textstellen vollst√§ndig",
      "Dokumentiere Begr√ºndung der Zuordnung"
    ],
    "exclusion": [
      "Literaturverzeichnisse und Referenzlisten",
      "Tabellarische Datenaufstellungen ohne Interpretation"
    ]
  }
}
```

### 8.2 Kategorienentwicklung

#### Hauptkategorien definieren

**Struktur einer Kategorie:**
```json
{
  "Kategorienname": {
    "definition": "Klare, pr√§zise Definition (min. 15 W√∂rter)",
    "rules": ["Spezifische Kodierregeln f√ºr diese Kategorie"],
    "examples": ["Konkretes Beispiel 1", "Konkretes Beispiel 2"],
    "subcategories": {
      "Subkategorie_1": "Beschreibung der Subkategorie",
      "Subkategorie_2": "Beschreibung der Subkategorie"
    }
  }
}
```

**Beispiel einer gut definierten Kategorie:**
```json
{
  "Akteure": {
    "definition": "Erfasst alle handelnden Personen, Gruppen oder Institutionen sowie deren Rollen, Beziehungen und Interaktionen im Kontext der digitalen Transformation",
    "rules": [
      "Codiere Aussagen zu: Individuen, Gruppen, Organisationen, Netzwerken",
      "Ber√ºcksichtige sowohl formelle als auch informelle Akteure",
      "Achte auf Machtbeziehungen und Hierarchien"
    ],
    "examples": [
      "Die Projektleiterin hat die Entscheidung f√ºr das neue LMS eigenst√§ndig getroffen",
      "Die Arbeitsgruppe Digitalisierung trifft sich w√∂chentlich zur Abstimmung",
      "Als Vermittler zwischen IT-Abteilung und Fakult√§t konnte er den Konflikt l√∂sen"
    ],
    "subcategories": {
      "Individuelle_Akteure": "Einzelpersonen wie Lehrende, Studierende, IT-Personal",
      "Kollektive_Akteure": "Gruppen, Organisationen, Institutionen wie Fakult√§ten",
      "Beziehungen": "Interaktionen, Hierarchien, Netzwerke zwischen Akteuren",
      "Rollen": "Formelle und informelle Positionen wie Innovationstreiber"
    }
  }
}
```

### 8.3 Qualit√§tskriterien f√ºr Kategorien

#### Definition (erforderlich)
- **Mindestl√§nge:** 15 W√∂rter
- **Klarheit:** Eindeutige Abgrenzung zu anderen Kategorien
- **Vollst√§ndigkeit:** Alle relevanten Aspekte erfasst
- **Operationalisierbarkeit:** Konkret anwendbar

#### Regeln (empfohlen)
- **Spezifit√§t:** Konkrete Anweisungen f√ºr diese Kategorie
- **Grenzf√§lle:** Hinweise f√ºr schwierige Entscheidungen
- **Ausschl√ºsse:** Was NICHT zur Kategorie geh√∂rt

#### Beispiele (erforderlich, min. 2)
- **Vielfalt:** Verschiedene Facetten der Kategorie zeigen
- **Realit√§tsn√§he:** Authentische, kontextnahe Beispiele
- **Grenzf√§lle:** Auch schwierige F√§lle illustrieren

#### Subkategorien (erforderlich, min. 2)
- **Vollst√§ndigkeit:** Alle wichtigen Aspekte abdecken
- **Trennsch√§rfe:** Klare Abgrenzung untereinander
- **Ausgewogenheit:** √Ñhnlicher Abstraktionsgrad

### 8.4 Codebook-Pflege und Iteration

#### Induktive Codes importieren

**[Screenshot-Platzhalter: Webapp Codebook-Tab mit Import-Button]**

1. **Automatische Erkennung:** Webapp scannt Output-Ordner nach induktiven Codes
2. **Import-Dialog:** Auswahl der Analyse-Datei mit gew√ºnschten Codes
3. **Vorschau:** √úberpr√ºfung der zu importierenden Codes
4. **Konflikt-Behandlung:** Umbenennungsoptionen bei Namenskonflikten
5. **Integration:** Codes werden in separater Sektion angezeigt

#### Iterative Verfeinerung

**Workflow:**
```
Iteration 1: Basis-Codebook (5 deduktive Kategorien)
    ‚Üì
Analyse mit abduktivem Modus
    ‚Üì
Import neuer Subkategorien (8 Kategorien total)
    ‚Üì
Iteration 2: Erweitertes Codebook
    ‚Üì
Weitere Analyse
    ‚Üì
S√§ttigung erreicht (keine neuen Kategorien)
```

#### Versionskontrolle

**Mit Git (empfohlen):**
```bash
# √Ñnderungen verfolgen
git add QCA-AID-Codebook.json
git commit -m "Kategorien 'Technologien' erweitert um KI-Subkategorien"

# Versionen vergleichen
git diff HEAD~1 QCA-AID-Codebook.json
```

**Manuelle Dokumentation:**
- √Ñnderungsprotokoll f√ºhren
- Begr√ºndungen f√ºr Anpassungen notieren
- Datum und Version dokumentieren

### 8.5 Validierung und Qualit√§tskontrolle

#### Automatische Validierung

QCA-AID pr√ºft automatisch:
- Mindestl√§nge von Definitionen
- Anzahl der Beispiele und Subkategorien
- √Ñhnlichkeit zwischen Kategorien
- Namenskonventionen

#### Manuelle √úberpr√ºfung

**Checkliste f√ºr Kategorien:**
- [ ] Definition ist klar und abgrenzend
- [ ] Mindestens 2 aussagekr√§ftige Beispiele
- [ ] Subkategorien decken Kategorie vollst√§ndig ab
- [ ] Keine √úberschneidungen mit anderen Kategorien
- [ ] Regeln sind operationalisierbar

**Checkliste f√ºr Gesamtsystem:**
- [ ] Alle Kategorien auf √§hnlichem Abstraktionsniveau
- [ ] System ist vollst√§ndig (alle relevanten Aspekte erfasst)
- [ ] System ist sparsam (keine redundanten Kategorien)
- [ ] Kategorien sind theoretisch fundiert

---

## 9. Arbeiten mit der Webapp

### 9.1 Webapp-√úbersicht

Die QCA-AID Webapp bietet eine intuitive Benutzeroberfl√§che mit vier Hauptbereichen:

**[Screenshot-Platzhalter: Webapp-Hauptansicht mit Tabs]**

1. **Konfiguration:** Technische Einstellungen und Modellauswahl
2. **Codebook:** Kategorienentwicklung und -verwaltung
3. **Analyse:** Durchf√ºhrung und √úberwachung von Analysen
4. **Explorer:** Ergebnisvisualisierung und -export

### 9.2 Projekt-Management

#### Projekt-Root festlegen

**[Screenshot-Platzhalter: Projekt-Verzeichnis-Dialog]**

1. **Verzeichnis w√§hlen:** Klick auf "üìÅ Projekt-Verzeichnis √§ndern"
2. **Ordner ausw√§hlen:** Navigation zum gew√ºnschten Projektordner
3. **Automatische Speicherung:** Einstellungen werden in `.qca-aid-project.json` gespeichert

**Empfohlene Projektstruktur:**
```
mein-forschungsprojekt/
‚îú‚îÄ‚îÄ input/                    # Eingabedateien
‚îÇ   ‚îú‚îÄ‚îÄ interviews/
‚îÇ   ‚îú‚îÄ‚îÄ documents/
‚îÇ   ‚îî‚îÄ‚îÄ transcripts/
‚îú‚îÄ‚îÄ output/                   # Analyseergebnisse
‚îú‚îÄ‚îÄ config/                   # Konfigurationsdateien
‚îú‚îÄ‚îÄ codebooks/               # Codebook-Versionen
‚îî‚îÄ‚îÄ .qca-aid-project.json    # Projekt-Einstellungen
```

### 9.3 Konfiguration-Tab

**[Screenshot-Platzhalter: Konfiguration-Tab mit Einstellungen]**

#### Datei-Browser verwenden

1. **Konfiguration laden:** Klick auf üìÅ neben Pfad-Eingabe
2. **Datei ausw√§hlen:** Navigation zu `.json` oder `.xlsx` Datei
3. **Automatische Erkennung:** Format wird automatisch erkannt
4. **Validierung:** Echtzeit-√úberpr√ºfung der Einstellungen

#### Modell-Einstellungen

**Cloud-Modelle:**
1. **Anbieter w√§hlen:** OpenAI, Anthropic, Mistral
2. **Modell ausw√§hlen:** Dropdown zeigt verf√ºgbare Modelle
3. **API-Key pr√ºfen:** Automatische Validierung

**Lokale Modelle:**
1. **"Local" ausw√§hlen:** Provider auf "Local (LM Studio/Ollama)" setzen
2. **Erkennung starten:** Klick auf "üîÑ Lokale Modelle erkennen"
3. **Modell w√§hlen:** Aus erkannten Modellen ausw√§hlen

#### Performance-Einstellungen

**[Screenshot-Platzhalter: Performance-Einstellungen Panel]**

- **Chunk-Gr√∂√üe:** Schieberegler f√ºr Textabschnittsgr√∂√üe
- **Batch-Gr√∂√üe:** Balance zwischen Geschwindigkeit und Qualit√§t
- **Kontextuelle Kodierung:** Toggle f√ºr erweiterten Kontext

### 9.4 Codebook-Tab

**[Screenshot-Platzhalter: Codebook-Editor mit Kategorien]**

#### Kategorien bearbeiten

1. **Neue Kategorie:** Klick auf "‚ûï Kategorie hinzuf√ºgen"
2. **Felder ausf√ºllen:**
   - Name (ohne Leerzeichen, Unterstriche verwenden)
   - Definition (mindestens 15 W√∂rter)
   - Regeln (optional, aber empfohlen)
   - Beispiele (mindestens 2)
   - Subkategorien (mindestens 2)

3. **Validierung:** Echtzeit-Feedback bei Eingabe
4. **Speichern:** Automatische Validierung vor Speicherung

#### Induktive Codes importieren

**[Screenshot-Platzhalter: Import-Dialog f√ºr induktive Codes]**

1. **Benachrichtigung beachten:** Info √ºber verf√ºgbare Codes
2. **Import starten:** Klick auf "Induktive Codes importieren"
3. **Datei ausw√§hlen:** Analyse-Datei mit gew√ºnschten Codes
4. **Vorschau pr√ºfen:** √úbersicht der zu importierenden Codes
5. **Konflikte l√∂sen:** Umbenennungsoptionen bei Namenskonflikten
6. **Import best√§tigen:** Codes werden in separater Sektion angezeigt

### 9.5 Analyse-Tab

**[Screenshot-Platzhalter: Analyse-Tab mit Fortschrittsanzeige]**

#### Eingabedateien verwalten

1. **Dateien √ºberpr√ºfen:** Liste aller Dateien im Input-Verzeichnis
2. **Vorschau anzeigen:** Klick auf Dateinamen f√ºr Textvorschau
3. **Attribute pr√ºfen:** Automatische Extraktion aus Dateinamen

#### Analyse starten

1. **Konfiguration pr√ºfen:** Gr√ºner Haken bei g√ºltiger Konfiguration
2. **Codebook validieren:** Gr√ºner Haken bei g√ºltigem Codebook
3. **Analyse starten:** Klick auf "üöÄ Analyse starten"
4. **Fortschritt verfolgen:** Echtzeit-Updates und Logs

#### Analyse √ºberwachen

**[Screenshot-Platzhalter: Fortschrittsbalken und Live-Logs]**

- **Fortschrittsbalken:** Visueller Fortschritt der Analyse
- **Live-Logs:** Detaillierte Informationen zum Analyseverlauf
- **Statistiken:** Token-Verbrauch, Geschwindigkeit, Kosten
- **Stopp-Funktion:** Analyse bei Bedarf unterbrechen

### 9.6 Explorer-Tab

**[Screenshot-Platzhalter: Explorer mit Ergebnis√ºbersicht]**

#### Ergebnisse durchsuchen

1. **Output-Dateien:** Liste aller Analyseergebnisse
2. **Datei-Vorschau:** Schnelle √úbersicht der Inhalte
3. **Metadaten:** Datum, Gr√∂√üe, Analysemodus
4. **Download:** Direkte Download-Links

#### Visualisierungen konfigurieren

1. **Explorer-Config laden:** Konfiguration f√ºr Diagramme
2. **Diagrammtypen w√§hlen:** Heatmaps, Netzwerke, Balkendiagramme
3. **Filter setzen:** Nach Kategorien, Attributen, Dokumenten
4. **Export:** Diagramme als PNG/PDF speichern

---

## 10. Output-Sheets und Ergebnisinterpretation

### 10.1 Struktur der Analyseergebnisse

QCA-AID erstellt eine umfassende Excel-Datei mit mehreren Arbeitsbl√§ttern:

**[Screenshot-Platzhalter: Excel-Datei mit Sheet-√úbersicht]**

#### Hauptergebnisse (Sheet: "Codings")

**Spaltenstruktur:**
- **Dokument:** Quelldatei des Textsegments
- **Chunk_ID:** Eindeutige Segment-Nummer
- **Text:** Originaltext des kodierten Segments
- **Hauptkategorie:** Zugewiesene Hauptkategorie
- **Subkategorie:** Zugewiesene Subkategorie
- **Konfidenz:** Sicherheit der Kodierung (0.0-1.0)
- **Coder_ID:** Identifikation des Kodierers
- **Begr√ºndung:** Erkl√§rung der Kodierentscheidung
- **Attribut_1/2/3:** Extrahierte Metadaten aus Dateinamen

**[Screenshot-Platzhalter: Codings-Sheet mit Beispieldaten]**

#### H√§ufigkeitsanalysen (Sheet: "Frequencies")

**Inhalte:**
- Absolute und relative H√§ufigkeiten pro Kategorie
- Verteilung nach Attributen (z.B. Hochschultyp, Position)
- Kreuztabellen zwischen Kategorien und Attributen
- Statistische Kennwerte (Mittelwerte, Standardabweichungen)

**[Screenshot-Platzhalter: Frequencies-Sheet mit Diagrammen]**

#### Intercoder-Reliabilit√§t (Sheet: "Reliability")

**Metriken:**
- **Cohens Kappa:** √úbereinstimmung zwischen Kodierern
- **Prozentuale √úbereinstimmung:** Einfache √úbereinstimmungsrate
- **Konfusionsmatrix:** Detaillierte √úbereinstimmungsanalyse
- **Kategoriespezifische Reliabilit√§t:** Reliabilit√§t pro Kategorie

**Interpretation:**
- **Œ∫ > 0.8:** Sehr gute √úbereinstimmung
- **Œ∫ 0.6-0.8:** Gute √úbereinstimmung
- **Œ∫ 0.4-0.6:** Moderate √úbereinstimmung
- **Œ∫ < 0.4:** Schlechte √úbereinstimmung (√úberarbeitung n√∂tig)

### 10.2 Induktive Kategorien (Sheet: "Inductive_Categories")

**[Screenshot-Platzhalter: Induktive Kategorien mit Entwicklungshistorie]**

#### Neue Hauptkategorien
- **Name:** Automatisch generierter Kategorienname
- **Definition:** KI-generierte Definition
- **H√§ufigkeit:** Anzahl der Zuordnungen
- **Beispiele:** Repr√§sentative Textstellen
- **Qualit√§tsbewertung:** Automatische Bewertung der Kategorie

#### Neue Subkategorien
- **Hauptkategorie:** Zugeh√∂rige √ºbergeordnete Kategorie
- **Subkategorie:** Name der neuen Subkategorie
- **Beschreibung:** Kurze Charakterisierung
- **Abgrenzung:** Unterscheidung zu bestehenden Subkategorien

### 10.3 Kategorienentwicklung (Sheet: "Category_Development")

**Dokumentation der Evolution:**
- **Iteration:** Analysedurchgang
- **√Ñnderungstyp:** Neue Kategorie, Modifikation, L√∂schung
- **Begr√ºndung:** KI-generierte Erkl√§rung
- **Auswirkung:** Anzahl betroffener Kodierungen

### 10.4 Qualit√§tsindikatoren interpretieren

#### Konfidenzwerte

**[Screenshot-Platzhalter: Konfidenzverteilung als Histogramm]**

- **Hoch (0.8-1.0):** Eindeutige Zuordnungen, hohe Sicherheit
- **Mittel (0.6-0.8):** Plausible Zuordnungen, moderate Sicherheit
- **Niedrig (0.4-0.6):** Unsichere Zuordnungen, manuelle Pr√ºfung empfohlen
- **Sehr niedrig (<0.4):** Problematische Zuordnungen, √úberarbeitung n√∂tig

#### Konsistenz-Metriken

**Intra-Coder-Konsistenz:**
- Vergleich desselben Kodierers bei √§hnlichen Textstellen
- Indikator f√ºr Regelklarheit und Kategorienqualit√§t

**Inter-Coder-Konsistenz:**
- √úbereinstimmung zwischen verschiedenen Kodierern
- Indikator f√ºr Objektivit√§t und Nachvollziehbarkeit

### 10.5 Ergebnisvalidierung

#### Stichprobenpr√ºfung

**Empfohlenes Vorgehen:**
1. **Zufallsstichprobe:** 10-20% der Kodierungen manuell pr√ºfen
2. **Niedrige Konfidenz:** Alle Kodierungen <0.6 √ºberpr√ºfen
3. **Neue Kategorien:** Alle induktiven Kategorien validieren
4. **Grenzf√§lle:** Kodierungen an Kategoriengrenzen pr√ºfen

#### Plausibilit√§tspr√ºfung

**Fragen zur Selbstreflexion:**
- Entsprechen die H√§ufigkeitsverteilungen den Erwartungen?
- Sind neue induktive Kategorien theoretisch sinnvoll?
- Gibt es unerwartete Muster in den Daten?
- Sind die Kodierungen nachvollziehbar begr√ºndet?

---
## 11. Optimaler Kodiermodus nach Forschungszielen

### 11.1 Entscheidungsmatrix f√ºr Kodiermodi

**[Screenshot-Platzhalter: Entscheidungsbaum f√ºr Modusauswahl]**

| Forschungsziel | Theoriestand | Datenmenge | Empfohlener Modus | Begr√ºndung |
|----------------|--------------|------------|-------------------|------------|
| **Theoriepr√ºfung** | Etabliert | Gro√ü | `deductive` | Maximale Vergleichbarkeit |
| **Theorieentwicklung** | Schwach | Mittel-Gro√ü | `full` | Offenheit f√ºr Neues |
| **Theoriemodifikation** | Moderat | Mittel | `abductive` | Balance Struktur/Offenheit |
| **Exploration** | Minimal | Klein-Mittel | `grounded` | Datengetriebene Entwicklung |
| **Replikation** | Etabliert | Beliebig | `deductive` | Exakte Vergleichbarkeit |
| **Methodenvergleich** | Etabliert | Gro√ü | `deductive` + `full` | Systematischer Vergleich |

### 11.2 Deduktiver Modus - Theoriepr√ºfung

#### Anwendungsszenarien

**Ideal f√ºr:**
- Hypothesenpr√ºfung mit etablierten Theorien
- Replikationsstudien
- Vergleichsstudien zwischen Gruppen/Zeitpunkten
- Standardisierte Inhaltsanalysen
- Evaluationsstudien mit festen Kriterien

**Beispiel-Forschungsfragen:**
- "Wie unterscheiden sich Digitalisierungsstrategien zwischen Universit√§ten und Fachhochschulen?"
- "Welche der theoretisch postulierten Barrieren zeigen sich empirisch?"
- "Haben sich die Herausforderungen seit 2020 ver√§ndert?"

#### Konfiguration

```json
{
  "ANALYSIS_MODE": "deductive",
  "CODER_SETTINGS": [
    {
      "temperature": 0.2,        // Niedrig f√ºr Konsistenz
      "coder_id": "deductive_1"
    },
    {
      "temperature": 0.3,        // Leicht variiert f√ºr Reliabilit√§t
      "coder_id": "deductive_2"
    }
  ],
  "REVIEW_MODE": "consensus",    // Nur √ºbereinstimmende Kodierungen
  "MULTIPLE_CODINGS": false     // Eine Kategorie pro Segment
}
```

#### Qualit√§tssicherung

- **Intercoder-Reliabilit√§t:** Mindestens Œ∫ > 0.7
- **Vollst√§ndige Abdeckung:** Alle Textstellen sollten kodierbar sein
- **Kategorienbalance:** Keine stark √ºber-/unterrepr√§sentierten Kategorien

### 11.3 Abduktiver Modus - Theoriemodifikation

#### Anwendungsszenarien

**Ideal f√ºr:**
- Verfeinerung bestehender Theorien
- Detaillierung bekannter Ph√§nomene
- Anpassung an neue Kontexte
- Explorative Vertiefung etablierter Konzepte

**Beispiel-Forschungsfragen:**
- "Welche spezifischen Formen von Digitalisierungsstrategien lassen sich unterscheiden?"
- "Wie differenzieren sich die bekannten Herausforderungen im Detail aus?"
- "Welche Subtypen von Akteuren sind relevant?"

#### Konfiguration

```json
{
  "ANALYSIS_MODE": "abductive",
  "CODER_SETTINGS": [
    {
      "temperature": 0.4,        // Moderat f√ºr Balance
      "coder_id": "abductive_1"
    },
    {
      "temperature": 0.5,        // Etwas kreativer
      "coder_id": "abductive_2"
    }
  ],
  "REVIEW_MODE": "majority",     // Mehrheitsentscheidung
  "MULTIPLE_CODINGS": true      // Mehrfachkodierungen m√∂glich
}
```

#### Besonderheiten

- **Subkategorien-Entwicklung:** Neue Subkategorien werden automatisch vorgeschlagen
- **Hauptkategorien bleiben:** Theoretische Struktur bleibt erhalten
- **Iterative Verfeinerung:** Mehrere Analysedurchg√§nge empfohlen

### 11.4 Induktiver Modus - Theorieentwicklung

#### Anwendungsszenarien

**Ideal f√ºr:**
- Entwicklung neuer Theorien
- Exploration unbekannter Ph√§nomene
- Entdeckung unerwarteter Muster
- Grounded Theory-Ans√§tze mit Vorstrukturierung

**Beispiel-Forschungsfragen:**
- "Welche Ph√§nomene zeigen sich bei der Digitalisierung von Hochschulen?"
- "Welche neuen Kategorien emergieren aus den Daten?"
- "Wie l√§sst sich das Ph√§nomen X theoretisch strukturieren?"

#### Konfiguration

```json
{
  "ANALYSIS_MODE": "full",
  "CODER_SETTINGS": [
    {
      "temperature": 0.6,        // H√∂her f√ºr Kreativit√§t
      "coder_id": "inductive_1"
    },
    {
      "temperature": 0.7,        // Noch kreativer
      "coder_id": "inductive_2"
    }
  ],
  "REVIEW_MODE": "manual",       // Manuelle √úberpr√ºfung n√∂tig
  "MULTIPLE_CODINGS": true,      // Mehrfachkodierungen erw√ºnscht
  "CODE_WITH_CONTEXT": true     // Kontext f√ºr bessere Kategorienbildung
}
```

#### Herausforderungen

- **√úberstrukturierung:** Gefahr zu vieler neuer Kategorien
- **Qualit√§tskontrolle:** Intensive manuelle Nachbearbeitung n√∂tig
- **Theoretische Integration:** Neue Kategorien m√ºssen theoretisch eingeordnet werden

### 11.5 Grounded Theory Modus - Datengetriebene Entwicklung

#### Anwendungsszenarien

**Ideal f√ºr:**
- Reine Grounded Theory-Studien
- Explorative Vorstudien
- Theorieentwicklung ohne Vorannahmen
- Entdeckung emergenter Ph√§nomene

**Beispiel-Forschungsfragen:**
- "Was passiert bei der Digitalisierung von Hochschulen?" (ohne Vorannahmen)
- "Welche Kategorien entwickeln sich aus den Daten?"
- "Wie strukturieren sich die Erfahrungen der Akteure?"

#### Konfiguration

```json
{
  "ANALYSIS_MODE": "grounded",
  "CODER_SETTINGS": [
    {
      "temperature": 0.8,        // Hoch f√ºr maximale Offenheit
      "coder_id": "grounded_1"
    }
  ],
  "REVIEW_MODE": "manual",       // Vollst√§ndige manuelle Kontrolle
  "MULTIPLE_CODINGS": true,
  "CODE_WITH_CONTEXT": true,
  "BATCH_SIZE": 3               // Kleinere Batches f√ºr Pr√§zision
}
```

#### Besonderheiten

- **Schrittweise Entwicklung:** Codes werden zun√§chst gesammelt, sp√§ter zu Hauptkategorien gruppiert
- **Iterative Analyse:** Mehrere Durchg√§nge mit Anpassung des Kategoriensystems
- **Theoretische S√§ttigung:** Analyse bis keine neuen Kategorien mehr entstehen

### 11.6 Materialspezifische Empfehlungen

#### Interview-Transkripte

**Charakteristika:**
- Dialogstruktur mit Fragen und Antworten
- Umgangssprache und F√ºllw√∂rter
- Subjektive Perspektiven und Erfahrungen

**Empfohlene Konfiguration:**
```json
{
  "CHUNK_SIZE": 1000,           // L√§ngere Chunks f√ºr Kontext
  "CHUNK_OVERLAP": 60,          // Mehr √úberlappung f√ºr Dialogkontinuit√§t
  "CODE_WITH_CONTEXT": true,    // Wichtig f√ºr Gespr√§chskontext
  "kodierregeln": {
    "exclusion": [
      "Interviewerfragen ohne inhaltlichen Bezug",
      "F√ºllw√∂rter und Pausen",
      "Technische Unterbrechungen"
    ]
  }
}
```

#### Akademische Texte

**Charakteristika:**
- Formale Sprache und Fachterminologie
- Strukturierte Argumentation
- Literaturverweise und Zitate

**Empfohlene Konfiguration:**
```json
{
  "CHUNK_SIZE": 1200,           // Gr√∂√üere Chunks f√ºr komplexe Argumente
  "CHUNK_OVERLAP": 40,          // Weniger √úberlappung bei klarer Struktur
  "CODE_WITH_CONTEXT": false,   // Weniger wichtig bei strukturierten Texten
  "kodierregeln": {
    "exclusion": [
      "Literaturverzeichnisse",
      "Methodische Beschreibungen",
      "Reine Zitate ohne Interpretation"
    ]
  }
}
```

#### Dokumente und Berichte

**Charakteristika:**
- Offizielle Sprache
- Strukturierte Gliederung
- Fakten und Empfehlungen

**Empfohlene Konfiguration:**
```json
{
  "CHUNK_SIZE": 800,            // Kleinere Chunks f√ºr pr√§zise Fakten
  "CHUNK_OVERLAP": 30,          // Minimale √úberlappung
  "MULTIPLE_CODINGS": false,    // Eindeutige Zuordnungen
  "kodierregeln": {
    "exclusion": [
      "Inhaltsverzeichnisse",
      "Tabellarische Auflistungen",
      "Formale Anh√§nge"
    ]
  }
}
```

#### Social Media und informelle Texte

**Charakteristika:**
- Kurze, fragmentierte Texte
- Umgangssprache und Slang
- Emotionale Ausdr√ºcke

**Empfohlene Konfiguration:**
```json
{
  "CHUNK_SIZE": 500,            // Kleine Chunks f√ºr kurze Posts
  "CHUNK_OVERLAP": 20,          // Minimale √úberlappung
  "BATCH_SIZE": 10,             // Mehr parallele Verarbeitung
  "CODER_SETTINGS": [
    {
      "temperature": 0.6,       // H√∂her f√ºr umgangssprachliche Nuancen
      "coder_id": "social_1"
    }
  ]
}
```

### 11.7 Kombinierte Ans√§tze

#### Sequenzielle Analyse

**Workflow:**
1. **Explorative Phase:** `grounded` Modus f√ºr erste Kategorienentwicklung
2. **Strukturierungsphase:** `abductive` Modus f√ºr Systematisierung
3. **Validierungsphase:** `deductive` Modus f√ºr finale √úberpr√ºfung

#### Parallele Analyse

**Vergleichende Kodierung:**
- Gleiche Daten mit verschiedenen Modi analysieren
- Systematischer Vergleich der Ergebnisse
- Triangulation f√ºr h√∂here Validit√§t

**Beispiel-Konfiguration:**
```json
{
  "ANALYSIS_CONFIGS": [
    {
      "name": "deductive_analysis",
      "ANALYSIS_MODE": "deductive",
      "OUTPUT_DIR": "output/deductive"
    },
    {
      "name": "inductive_analysis", 
      "ANALYSIS_MODE": "full",
      "OUTPUT_DIR": "output/inductive"
    }
  ]
}
```

---

## 12. Best Practices und Qualit√§tssicherung

### 12.1 Vorbereitung der Datengrundlage

#### Textqualit√§t sicherstellen

**Dokumentenvorbereitung:**
- **Bereinigung:** Entfernung von Literaturverzeichnissen, Fu√ünoten, Seitenzahlen
- **Formatierung:** Einheitliche Textformatierung, keine Sonderzeichen
- **Vollst√§ndigkeit:** √úberpr√ºfung auf fehlende Textpassagen (besonders bei PDFs)
- **Kodierung:** UTF-8 Encoding f√ºr Umlaute und Sonderzeichen

**[Screenshot-Platzhalter: Beispiel f√ºr bereinigte vs. unbereinigte Dokumente]**

#### Dateiorganisation

**Namenskonvention:**
```
Attribut1_Attribut2_Attribut3_Bezeichnung.txt

Beispiele:
Universit√§t_Professor_Informatik_Interview_2024-01-15.txt
FH_Studierende_BWL_Fokusgruppe_2024-02-20.txt
Ministerium_Referent_Politik_Dokument_2024-03-10.txt
```

**Verzeichnisstruktur:**
```
projekt/
‚îú‚îÄ‚îÄ input/
‚îÇ   ‚îú‚îÄ‚îÄ interviews/           # Nach Datentyp organisiert
‚îÇ   ‚îú‚îÄ‚îÄ documents/
‚îÇ   ‚îî‚îÄ‚îÄ focus_groups/
‚îú‚îÄ‚îÄ output/
‚îÇ   ‚îú‚îÄ‚îÄ 2024-01-15_analysis/  # Nach Datum organisiert
‚îÇ   ‚îî‚îÄ‚îÄ 2024-02-20_analysis/
‚îî‚îÄ‚îÄ codebooks/
    ‚îú‚îÄ‚îÄ v1.0_initial.json     # Versionierte Codebooks
    ‚îú‚îÄ‚îÄ v1.1_refined.json
    ‚îî‚îÄ‚îÄ v2.0_final.json
```

### 12.2 Iterative Qualit√§tssicherung

#### Pilotphase (10-20% der Daten)

**Ziele:**
- Kategorienqualit√§t testen
- Kodierregeln verfeinern
- Technische Parameter optimieren
- Erste Reliabilit√§tspr√ºfung

**Vorgehen:**
1. **Stichprobe ziehen:** Repr√§sentative Auswahl der Dokumente
2. **Erste Kodierung:** Mit vorl√§ufigem Codebook
3. **Manuelle √úberpr√ºfung:** 100% der Pilotdaten manuell pr√ºfen
4. **Anpassungen:** Kategorien und Regeln √ºberarbeiten
5. **Wiederholung:** Bis zufriedenstellende Qualit√§t erreicht

#### Hauptanalyse mit Stichprobenkontrolle

**Qualit√§tskontrolle w√§hrend der Analyse:**
- **10% Stichprobe:** Zuf√§llige Auswahl f√ºr manuelle √úberpr√ºfung
- **Niedrige Konfidenz:** Alle Kodierungen <0.6 pr√ºfen
- **Neue Kategorien:** Alle induktiven Kategorien validieren
- **Grenzf√§lle:** Kodierungen an Kategoriengrenzen kontrollieren

**[Screenshot-Platzhalter: Qualit√§tskontroll-Dashboard in der Webapp]**

### 12.3 Intercoder-Reliabilit√§t optimieren

#### Mehrere KI-Codierer konfigurieren

**Empfohlene Konfiguration:**
```json
{
  "CODER_SETTINGS": [
    {
      "temperature": 0.3,
      "coder_id": "conservative",
      "description": "Konservativer Kodierer f√ºr eindeutige F√§lle"
    },
    {
      "temperature": 0.5,
      "coder_id": "balanced", 
      "description": "Ausgewogener Kodierer f√ºr Standardf√§lle"
    },
    {
      "temperature": 0.7,
      "coder_id": "creative",
      "description": "Kreativer Kodierer f√ºr Grenzf√§lle"
    }
  ]
}
```

#### Konsensbildung konfigurieren

**Review-Modi:**
- **`consensus`:** Nur √ºbereinstimmende Kodierungen (h√∂chste Qualit√§t)
- **`majority`:** Mehrheitsentscheidung bei 3+ Kodierern
- **`weighted`:** Gewichtung nach Kodierer-Performance
- **`manual`:** Manuelle Entscheidung bei Konflikten

#### Reliabilit√§ts-Benchmarks

**Interpretationshilfen:**
- **Œ∫ > 0.8:** Exzellente √úbereinstimmung ‚Üí Analyse fortsetzen
- **Œ∫ 0.6-0.8:** Gute √úbereinstimmung ‚Üí Stichprobenkontrolle
- **Œ∫ 0.4-0.6:** Moderate √úbereinstimmung ‚Üí Kategorien √ºberarbeiten
- **Œ∫ < 0.4:** Schlechte √úbereinstimmung ‚Üí Grundlegende √úberarbeitung n√∂tig

### 12.4 Kategorienqualit√§t sicherstellen

#### Validierungscheckliste

**F√ºr jede Kategorie pr√ºfen:**
- [ ] **Definition:** Klar, abgrenzend, mindestens 15 W√∂rter
- [ ] **Operationalisierung:** Konkret anwendbare Regeln
- [ ] **Beispiele:** Mindestens 2, verschiedene Facetten zeigend
- [ ] **Abgrenzung:** Keine √úberschneidungen mit anderen Kategorien
- [ ] **Vollst√§ndigkeit:** Alle relevanten Aspekte erfasst
- [ ] **Theoretische Fundierung:** Bezug zu Forschungsstand

#### Kategorienoptimierung

**H√§ufige Probleme und L√∂sungen:**

| Problem | Symptom | L√∂sung |
|---------|---------|--------|
| **Zu breite Kategorie** | >40% aller Kodierungen | Aufteilen in Subkategorien |
| **Zu enge Kategorie** | <2% aller Kodierungen | Mit √§hnlicher Kategorie zusammenfassen |
| **√úberschneidungen** | Niedrige Intercoder-Reliabilit√§t | Abgrenzungskriterien sch√§rfen |
| **Unklare Definition** | Inkonsistente Kodierungen | Definition pr√§zisieren, Beispiele erg√§nzen |
| **Fehlende Kategorie** | Viele "Sonstige"-Kodierungen | Neue Kategorie entwickeln |

### 12.5 Technische Optimierung

#### Performance-Tuning

**Batch-Gr√∂√üe optimieren:**
```python
# Testlauf mit verschiedenen Batch-Gr√∂√üen
batch_sizes = [3, 5, 8, 10, 12]
for size in batch_sizes:
    # Zeitmessung und Qualit√§tsbewertung
    # Optimale Balance finden
```

**Chunk-Parameter anpassen:**
- **Zu kleine Chunks:** Kontextverlust, fragmentierte Kodierungen
- **Zu gro√üe Chunks:** Mehrfachkodierungen, unklare Zuordnungen
- **Optimale Gr√∂√üe:** 800-1200 Zeichen je nach Texttyp

#### Kostenoptimierung

**Token-Verbrauch reduzieren:**
- **Pr√§zise Kategorien:** Weniger Nachfragen durch klarere Definitionen
- **Optimale Batch-Gr√∂√üe:** Weniger API-Calls durch gr√∂√üere Batches
- **G√ºnstigere Modelle:** F√ºr einfache Kodierungen ausreichend
- **Lokale Modelle:** Kostenlos f√ºr sensible oder gro√üe Datenmengen

**[Screenshot-Platzhalter: Token-Tracking und Kosten√ºbersicht]**

### 12.6 Dokumentation und Nachvollziehbarkeit

#### Analysedokumentation

**Pflichtangaben:**
- **Codebook-Version:** Mit Datum und √Ñnderungshistorie
- **Konfiguration:** Vollst√§ndige technische Parameter
- **Stichprobenkontrolle:** Umfang und Ergebnisse der manuellen Pr√ºfung
- **Reliabilit√§tswerte:** Intercoder-√úbereinstimmung pro Kategorie
- **Anpassungen:** Alle √Ñnderungen am Kategoriensystem dokumentieren

#### Forschungstagebuch f√ºhren

**Empfohlene Eintr√§ge:**
```
Datum: 2024-01-15
Aktivit√§t: Pilotanalyse Interview-Daten
Ergebnisse: Œ∫ = 0.65, Kategorie "Technologien" zu breit
Anpassungen: Aufgeteilt in "Hardware" und "Software"
N√§chste Schritte: Wiederholung mit angepasstem Codebook

Datum: 2024-01-20
Aktivit√§t: Hauptanalyse Batch 1-3
Ergebnisse: Œ∫ = 0.78, neue induktive Kategorie "KI-Tools"
Beobachtungen: H√§ufige Erw√§hnung von ChatGPT und √§hnlichen Tools
Entscheidung: Kategorie ins Codebook aufnehmen
```

#### Reproduzierbarkeit sicherstellen

**Versionskontrolle:**
```bash
# Git-Repository f√ºr Projekt
git init
git add .
git commit -m "Initial codebook v1.0"

# √Ñnderungen dokumentieren
git add QCA-AID-Codebook.json
git commit -m "Added AI-Tools subcategory to Technologies"

# Tags f√ºr wichtige Versionen
git tag -a v1.0 -m "Final codebook for main analysis"
```

**Konfiguration archivieren:**
- Vollst√§ndige Konfigurationsdateien speichern
- Screenshots der Webapp-Einstellungen
- Verwendete Modellversionen dokumentieren
- API-Parameter und Batch-Gr√∂√üen notieren

---
## 13. H√§ufige Probleme und L√∂sungen

### 13.1 Installation und Setup

#### Problem: Python-Versionskonflikte

**Symptom:** `ModuleNotFoundError` oder Kompatibilit√§tsfehler

**Ursache:** Python 3.13 oder inkompatible Versionen

**L√∂sung:**
```bash
# Python-Version pr√ºfen
python --version

# Falls Python 3.13: Python 3.11 installieren
# Download von python.org/downloads/release/python-3110/

# Virtuelle Umgebung mit korrekter Version
python3.11 -m venv qca_aid_env
source qca_aid_env/bin/activate  # Linux/Mac
qca_aid_env\Scripts\activate     # Windows

# Abh√§ngigkeiten neu installieren
pip install -r requirements.txt
```

#### Problem: spaCy-Installation fehlgeschlagen

**Symptom:** `OSError: [E050] Can't find model 'de_core_news_sm'`

**L√∂sung:**
```bash
# Deutsches Sprachmodell installieren
python -m spacy download de_core_news_sm

# Falls Fehler: Direkt von GitHub installieren
pip install https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl
```

#### Problem: Visual C++ Build Tools fehlen (Windows)

**Symptom:** `Microsoft Visual C++ 14.0 is required`

**L√∂sung:**
1. **Build Tools installieren:** [Visual Studio Build Tools](https://visualstudio.microsoft.com/de/visual-cpp-build-tools/)
2. **C++ Build Tools** aktivieren
3. **MSVC** und **Windows SDK** ausw√§hlen
4. **Alternative:** Anaconda verwenden (enth√§lt vorkompilierte Pakete)

### 13.2 API und Authentifizierung

#### Problem: API-Schl√ºssel nicht gefunden

**Symptom:** `OpenAI API key not found` oder `Authentication failed`

**L√∂sung:**
```bash
# .env-Datei im Projektverzeichnis erstellen
echo "OPENAI_API_KEY=sk-proj-..." > .env
echo "ANTHROPIC_API_KEY=sk-ant-..." >> .env

# Oder Umgebungsvariable setzen (Windows)
setx OPENAI_API_KEY "sk-proj-..."

# Oder Umgebungsvariable setzen (Linux/Mac)
export OPENAI_API_KEY="sk-proj-..."
```

#### Problem: Rate Limit exceeded

**Symptom:** `Rate limit reached for requests`

**L√∂sung:**
```json
{
  "BATCH_SIZE": 3,              // Reduzieren f√ºr weniger parallele Anfragen
  "REQUEST_DELAY": 1.0,         // Pause zwischen Anfragen (Sekunden)
  "MAX_RETRIES": 5              // Mehr Wiederholungsversuche
}
```

#### Problem: Context length exceeded

**Symptom:** `This model's maximum context length is X tokens`

**L√∂sung:**
```json
{
  "CHUNK_SIZE": 800,            // Kleinere Chunks verwenden
  "CODE_WITH_CONTEXT": false,   // Kontext deaktivieren
  "BATCH_SIZE": 3               // Weniger Chunks pro Anfrage
}
```

### 13.3 Webapp-spezifische Probleme

#### Problem: Webapp startet nicht

**Symptom:** `ModuleNotFoundError: No module named 'streamlit'`

**L√∂sung:**
```bash
# Streamlit installieren
pip install streamlit

# Oder alle Abh√§ngigkeiten neu installieren
pip install -r requirements.txt

# Webapp starten
cd QCA_AID_app
python start_webapp.py
```

#### Problem: Port bereits belegt

**Symptom:** `Port 8501 is already in use`

**L√∂sung:**
```bash
# Andere Streamlit-Instanzen beenden
pkill -f streamlit  # Linux/Mac
taskkill /f /im python.exe  # Windows (alle Python-Prozesse)

# Oder anderen Port verwenden
streamlit run webapp.py --server.port 8502
```

#### Problem: Datei-Browser √∂ffnet nicht

**Symptom:** Klick auf üìÅ zeigt keinen Dialog

**L√∂sung:**
```bash
# tkinter testen
python -m tkinter

# Falls Fehler (Linux):
sudo apt-get install python3-tk

# Falls Fehler (Mac):
# Python von python.org neu installieren

# Alternative: Pfade manuell eingeben
```

### 13.4 Konfiguration und Codebook

#### Problem: JSON-Syntax-Fehler

**Symptom:** `JSONDecodeError: Expecting ',' delimiter`

**H√§ufige Fehler:**
```json
// FALSCH: Trailing Comma
{
  "CHUNK_SIZE": 1000,
  "BATCH_SIZE": 5,  // ‚Üê Komma am Ende
}

// RICHTIG:
{
  "CHUNK_SIZE": 1000,
  "BATCH_SIZE": 5
}

// FALSCH: Einfache Anf√ºhrungszeichen
{
  'MODEL_PROVIDER': 'OpenAI'  // ‚Üê Einfache Anf√ºhrungszeichen
}

// RICHTIG:
{
  "MODEL_PROVIDER": "OpenAI"
}
```

**L√∂sung:**
- **Online-Validator:** [jsonlint.com](https://jsonlint.com/)
- **VS Code:** JSON-Syntax-Highlighting aktivieren
- **Python-Test:** `json.load()` zum Testen verwenden

#### Problem: Kategorien-Validierung fehlgeschlagen

**Symptom:** `Definition zu kurz` oder `Zu wenige Beispiele`

**L√∂sung:**
```json
{
  "Kategorie_Name": {
    "definition": "Mindestens 15 W√∂rter f√ºr eine vollst√§ndige und pr√§zise Definition der Kategorie mit klarer Abgrenzung zu anderen Kategorien",
    "examples": [
      "Erstes konkretes Beispiel f√ºr die Kategorie",
      "Zweites Beispiel mit anderem Fokus",
      "Drittes Beispiel f√ºr Grenzfall"
    ],
    "subcategories": {
      "Sub_1": "Erste Subkategorie",
      "Sub_2": "Zweite Subkategorie"
    }
  }
}
```

### 13.5 Analyse-Probleme

#### Problem: Keine Eingabedateien gefunden

**Symptom:** `No input files found in directory`

**L√∂sung:**
```bash
# Verzeichnisstruktur pr√ºfen
ls -la input/  # Linux/Mac
dir input\     # Windows

# Unterst√ºtzte Formate: .txt, .pdf, .docx
# Dateien in input/ Verzeichnis kopieren

# Pfad in Konfiguration pr√ºfen
{
  "DATA_DIR": "input"  // Relativ zum Projektverzeichnis
}
```

#### Problem: PDF-Texte nicht lesbar

**Symptom:** Leere oder verst√ºmmelte Texte aus PDF-Dateien

**L√∂sung:**
1. **PDF-Qualit√§t pr√ºfen:** Enth√§lt die PDF Textebene oder nur Bilder?
2. **OCR verwenden:** F√ºr gescannte PDFs externe OCR-Software nutzen
3. **Als Text exportieren:** PDF in Word √∂ffnen und als .txt speichern
4. **Alternative Tools:** Adobe Acrobat, PDFtk, oder Online-Konverter

#### Problem: Analyse bricht ab

**Symptom:** `Analysis stopped unexpectedly` oder Timeout-Fehler

**M√∂gliche Ursachen und L√∂sungen:**

**Netzwerkprobleme:**
```json
{
  "MAX_RETRIES": 10,           // Mehr Wiederholungsversuche
  "RETRY_DELAY": 5,            // L√§ngere Wartezeit zwischen Versuchen
  "TIMEOUT": 120               // L√§ngerer Timeout (Sekunden)
}
```

**Speicherprobleme:**
```json
{
  "BATCH_SIZE": 3,             // Kleinere Batches
  "CHUNK_SIZE": 800,           // Kleinere Chunks
  "PARALLEL_WORKERS": 1        // Weniger parallele Prozesse
}
```

**API-Limits:**
```json
{
  "REQUEST_DELAY": 2.0,        // L√§ngere Pausen zwischen Anfragen
  "BATCH_SIZE": 2              // Sehr kleine Batches
}
```

### 13.6 Ergebnis-Probleme

#### Problem: Niedrige Intercoder-Reliabilit√§t

**Symptom:** Œ∫ < 0.6 zwischen Kodierern

**Diagnose und L√∂sungen:**

**Kategorien zu unscharf:**
```json
// Vorher: Unscharf
{
  "Technologie": {
    "definition": "Alles was mit Technik zu tun hat"
  }
}

// Nachher: Pr√§zise
{
  "Technologie": {
    "definition": "Konkrete digitale Werkzeuge, Software und Hardware, die aktiv in Lehr- oder Verwaltungsprozessen eingesetzt werden",
    "rules": [
      "Codiere nur explizit genannte Technologien",
      "Unterscheide zwischen geplanter und tats√§chlicher Nutzung"
    ]
  }
}
```

**Zu viele Grenzf√§lle:**
- Kategorien √ºberarbeiten und sch√§rfer abgrenzen
- Mehr Beispiele f√ºr typische und Grenzf√§lle
- Ausschlusskriterien definieren

#### Problem: Zu viele induktive Kategorien

**Symptom:** >20 neue Kategorien bei induktiver Analyse

**L√∂sung:**
```json
{
  "ANALYSIS_MODE": "abductive",     // Weniger offener Modus
  "CODER_SETTINGS": [
    {
      "temperature": 0.4,           // Weniger kreativ
      "min_frequency": 3            // Mindesth√§ufigkeit f√ºr neue Kategorien
    }
  ]
}
```

**Nachbearbeitung:**
- √Ñhnliche Kategorien zusammenfassen
- Seltene Kategorien (<2% der Kodierungen) pr√ºfen
- Hierarchische Struktur entwickeln

#### Problem: Unplausible Kodierungen

**Symptom:** Kodierungen entsprechen nicht den Erwartungen

**Systematische √úberpr√ºfung:**
1. **Stichprobe ziehen:** 20-30 zuf√§llige Kodierungen
2. **Manuell bewerten:** Sind die Zuordnungen nachvollziehbar?
3. **Muster identifizieren:** Welche Kategorien sind besonders problematisch?
4. **Ursachen analysieren:** Unklare Definitionen? Schlechte Beispiele?

**H√§ufige Ursachen:**
- **Zu abstrakte Kategorien:** Konkretere Definitionen entwickeln
- **Fehlende Beispiele:** Mehr und bessere Beispiele hinzuf√ºgen
- **√úberschneidende Kategorien:** Abgrenzungskriterien sch√§rfen
- **Ungeeignetes Modell:** Besseres/gr√∂√üeres Modell verwenden

### 13.7 Performance-Probleme

#### Problem: Sehr langsame Analyse

**Symptom:** <10 Chunks pro Minute verarbeitet

**Optimierungsma√ünahmen:**

**Batch-Gr√∂√üe erh√∂hen:**
```json
{
  "BATCH_SIZE": 12,             // Mehr parallele Verarbeitung
  "PARALLEL_WORKERS": 4         // Mehr Worker-Threads
}
```

**Modell wechseln:**
```json
{
  "MODEL_NAME": "gpt-4o-mini"   // Schnelleres Modell statt gpt-4o
}
```

**Lokale Modelle nutzen:**
```json
{
  "MODEL_PROVIDER": "local",
  "MODEL_NAME": "llama3.1:8b"  // Lokales Modell ohne API-Latenz
}
```

#### Problem: Hohe Kosten

**Symptom:** Unerwartete API-Kosten

**Kostenoptimierung:**
```json
{
  "MODEL_NAME": "gpt-4o-mini",      // G√ºnstigeres Modell
  "BATCH_SIZE": 10,                 // Weniger API-Calls
  "CHUNK_SIZE": 800,                // Kleinere Chunks = weniger Tokens
  "CODE_WITH_CONTEXT": false        // Kontext spart Tokens
}
```

**Kostenkontrolle:**
- **Token-Tracking:** Verbrauch in Echtzeit √ºberwachen
- **Budgetlimits:** API-Limits beim Anbieter setzen
- **Testl√§ufe:** Kleine Stichproben vor Vollanalyse
- **Lokale Modelle:** F√ºr gro√üe Projekte kostenlos

### 13.8 Debugging und Diagnose

#### Debug-Modus aktivieren

```json
{
  "DEBUG_MODE": true,
  "LOG_LEVEL": "DEBUG",
  "SAVE_INTERMEDIATE": true     // Zwischenergebnisse speichern
}
```

#### Log-Dateien analysieren

**Wichtige Log-Dateien:**
```bash
# QCA-AID Logs
cat .crush/logs/crush.log

# Webapp Logs
cat ~/.streamlit/logs/streamlit.log

# Python Fehler
python QCA-AID.py 2>&1 | tee debug.log
```

#### Systematische Fehlersuche

**Schritt-f√ºr-Schritt-Diagnose:**
1. **Minimalkonfiguration:** Einfachste Einstellungen testen
2. **Einzelne Datei:** Nur eine Eingabedatei verwenden
3. **Kleine Chunks:** CHUNK_SIZE auf 200 reduzieren
4. **Einzelner Coder:** Nur einen Kodierer verwenden
5. **Deduktiver Modus:** Komplexit√§t reduzieren

**Isolierung von Problemen:**
```json
// Minimale Testkonfiguration
{
  "MODEL_PROVIDER": "OpenAI",
  "MODEL_NAME": "gpt-4o-mini",
  "CHUNK_SIZE": 200,
  "BATCH_SIZE": 1,
  "ANALYSIS_MODE": "deductive",
  "CODE_WITH_CONTEXT": false,
  "CODER_SETTINGS": [
    {
      "temperature": 0.3,
      "coder_id": "test"
    }
  ]
}
```

### 13.9 Notfall-Wiederherstellung

#### Analyse-Unterbrechung

**Automatische Wiederherstellung:**
- QCA-AID speichert Fortschritt automatisch
- Bei Neustart wird an letzter Position fortgesetzt
- Zwischenergebnisse in `output/temp/` verf√ºgbar

**Manuelle Wiederherstellung:**
```bash
# Letzte Sicherung finden
ls -la output/temp/

# Fortschritt pr√ºfen
grep "Progress:" output/temp/analysis_log.txt

# Analyse fortsetzen
python QCA-AID.py --resume
```

#### Korrupte Konfiguration

**Backup wiederherstellen:**
```bash
# Git-Versionen pr√ºfen
git log --oneline QCA-AID-Codebook.json

# Letzte funktionierende Version wiederherstellen
git checkout HEAD~1 QCA-AID-Codebook.json
```

**Neu erstellen:**
1. **Beispielkonfiguration kopieren:** `examples/config-standard.json`
2. **Schrittweise anpassen:** Nur notwendige √Ñnderungen
3. **Validierung:** Nach jeder √Ñnderung testen

---

## 14. Anhang: Screenshots und Beispiele

### 14.1 Screenshot-Platzhalter

**Hinweis:** Die folgenden Bereiche sind f√ºr Screenshots vorgesehen, die Sie nach der Erstellung des Handbuchs einf√ºgen k√∂nnen:

#### Installation und Setup
- [ ] **Python-Installation:** Download-Seite und Installationsoptionen
- [ ] **Verzeichnisstruktur:** Beispiel eines organisierten Projektordners
- [ ] **Erste Webapp-Ansicht:** Startbildschirm nach erfolgreicher Installation

#### Webapp-Bedienung
- [ ] **Hauptnavigation:** √úbersicht der vier Haupttabs
- [ ] **Projekt-Dialog:** Auswahl des Projekt-Root-Verzeichnisses
- [ ] **Datei-Browser:** Native Dateiauswahl-Dialoge
- [ ] **Konfiguration-Tab:** Vollst√§ndige Ansicht aller Einstellungen
- [ ] **Modell-Auswahl:** Dropdown mit verf√ºgbaren Modellen
- [ ] **Lokale Modelle:** Erkennungs-Dialog f√ºr LM Studio/Ollama

#### Codebook-Entwicklung
- [ ] **Codebook-Editor:** Kategorien-Eingabeformular
- [ ] **Validierung:** Echtzeit-Feedback bei Eingabefehlern
- [ ] **Import-Dialog:** Induktive Codes aus vorherigen Analysen
- [ ] **JSON-Vorschau:** Strukturansicht des Codebooks
- [ ] **Kategorien-√úbersicht:** Liste aller definierten Kategorien

#### Analyse-Durchf√ºhrung
- [ ] **Eingabedateien:** Liste mit Dateivorschau
- [ ] **Analyse-Start:** Konfigurationspr√ºfung und Start-Button
- [ ] **Fortschrittsanzeige:** Live-Updates w√§hrend der Analyse
- [ ] **Log-Ausgabe:** Detaillierte Fortschrittsinformationen
- [ ] **Fehlerbehandlung:** Beispiele f√ºr Fehlermeldungen und L√∂sungen

#### Ergebnisse und Output
- [ ] **Excel-√úbersicht:** Struktur der Ergebnisdatei mit Sheets
- [ ] **Codings-Sheet:** Beispieldaten mit Kodierungen
- [ ] **H√§ufigkeitsanalyse:** Diagramme und Statistiken
- [ ] **Reliabilit√§ts-Report:** Intercoder-√úbereinstimmung
- [ ] **Induktive Kategorien:** Neu entwickelte Kategorien

#### Explorer und Visualisierung
- [ ] **Explorer-√úbersicht:** Ergebnisdateien und Metadaten
- [ ] **Diagramm-Konfiguration:** Einstellungen f√ºr Visualisierungen
- [ ] **Netzwerk-Analyse:** Beispiel einer Akteurs-Netzwerk-Visualisierung
- [ ] **Heatmap:** Kategorie-H√§ufigkeiten nach Attributen
- [ ] **Export-Optionen:** Download und Sharing-Funktionen

### 14.2 Beispiel-Konfigurationen

#### Beispiel 1: Interview-Studie zur Hochschuldigitalisierung

**Forschungskontext:**
- 15 Experteninterviews mit Hochschulleitungen
- Deduktive Analyse mit etabliertem Kategoriensystem
- Fokus auf Strategien und Herausforderungen

**Konfiguration:**
```json
{
  "forschungsfrage": "Welche Digitalisierungsstrategien verfolgen deutsche Hochschulen und welche Herausforderungen identifizieren die Leitungen?",
  "config": {
    "MODEL_PROVIDER": "OpenAI",
    "MODEL_NAME": "gpt-4o-mini",
    "CHUNK_SIZE": 1000,
    "CHUNK_OVERLAP": 50,
    "BATCH_SIZE": 5,
    "ANALYSIS_MODE": "deductive",
    "CODE_WITH_CONTEXT": true,
    "ATTRIBUTE_LABELS": {
      "attribut1": "Hochschultyp",
      "attribut2": "Bundesland",
      "attribut3": "Gr√∂√üe"
    }
  }
}
```

#### Beispiel 2: Explorative Dokumentenanalyse

**Forschungskontext:**
- Analyse von Strategiepapieren und Berichten
- Induktive Kategorienentwicklung
- Grounded Theory-Ansatz

**Konfiguration:**
```json
{
  "forschungsfrage": "Welche Themen und Muster zeigen sich in den Digitalisierungsstrategien deutscher Hochschulen?",
  "config": {
    "MODEL_PROVIDER": "local",
    "MODEL_NAME": "llama3.1:8b",
    "CHUNK_SIZE": 1200,
    "CHUNK_OVERLAP": 60,
    "BATCH_SIZE": 3,
    "ANALYSIS_MODE": "grounded",
    "CODE_WITH_CONTEXT": true,
    "CODER_SETTINGS": [
      {
        "temperature": 0.7,
        "coder_id": "explorative"
      }
    ]
  }
}
```

#### Beispiel 3: Vergleichsstudie mit Mehrfachkodierung

**Forschungskontext:**
- Vergleich zwischen Universit√§ten und Fachhochschulen
- Hohe Qualit√§tsanforderungen durch Mehrfachkodierung
- Fokus auf Intercoder-Reliabilit√§t

**Konfiguration:**
```json
{
  "config": {
    "MODEL_PROVIDER": "Anthropic",
    "MODEL_NAME": "claude-3-5-sonnet-20241022",
    "ANALYSIS_MODE": "abductive",
    "REVIEW_MODE": "consensus",
    "CODER_SETTINGS": [
      {
        "temperature": 0.3,
        "coder_id": "conservative"
      },
      {
        "temperature": 0.4,
        "coder_id": "moderate"
      },
      {
        "temperature": 0.5,
        "coder_id": "liberal"
      }
    ]
  }
}
```

### 14.3 Musterdokumente

#### Beispiel-Codebook: Hochschuldigitalisierung

**Vollst√§ndiges Kategoriensystem:**
```json
{
  "deduktive_kategorien": {
    "Strategien": {
      "definition": "Geplante und systematische Ans√§tze zur Gestaltung der digitalen Transformation in Hochschulen, einschlie√ülich Zielsetzungen, Ma√ünahmen und Umsetzungspl√§nen",
      "rules": [
        "Codiere sowohl explizite Strategiedokumente als auch implizite strategische √úberlegungen",
        "Unterscheide zwischen Top-down und Bottom-up Strategien",
        "Ber√ºcksichtige zeitliche Dimensionen (kurz-, mittel-, langfristig)"
      ],
      "examples": [
        "Die Hochschule hat eine umfassende Digitalisierungsstrategie bis 2030 entwickelt",
        "Durch dezentrale Pilotprojekte sollen Best Practices identifiziert werden",
        "Die IT-Strategie sieht eine schrittweise Migration in die Cloud vor"
      ],
      "subcategories": {
        "Top_Down": "Von der Hochschulleitung initiierte und gesteuerte Strategien",
        "Bottom_Up": "Aus den Fakult√§ten und Bereichen entwickelte Ans√§tze",
        "Partizipativ": "Gemeinsam entwickelte Strategien mit breiter Beteiligung",
        "Adaptiv": "Flexible, sich anpassende Strategieans√§tze"
      }
    },
    "Technologien": {
      "definition": "Konkrete digitale Werkzeuge, Plattformen, Systeme und Infrastrukturen, die in Hochschulen eingesetzt werden oder deren Einsatz geplant ist",
      "rules": [
        "Codiere sowohl Hardware als auch Software",
        "Ber√ºcksichtige auch geplante oder diskutierte Technologien",
        "Unterscheide zwischen Kern-IT und fachspezifischen Tools"
      ],
      "examples": [
        "Das Learning Management System Moodle wird campusweit genutzt",
        "Neue Videokonferenz-R√§ume erm√∂glichen hybride Lehre",
        "KI-Tools wie ChatGPT werden in der Lehre erprobt"
      ],
      "subcategories": {
        "Lernplattformen": "LMS, E-Learning-Systeme, digitale Lernumgebungen",
        "Kommunikation": "Videokonferenz, Chat, Kollaborationstools",
        "Infrastruktur": "Server, Netzwerke, Cloud-Services, Hardware",
        "KI_Tools": "K√ºnstliche Intelligenz und maschinelles Lernen"
      }
    }
  }
}
```

### 14.4 Checklisten und Vorlagen

#### Projekt-Setup Checkliste

**Vor der ersten Analyse:**
- [ ] Python 3.10/3.11 installiert und getestet
- [ ] QCA-AID heruntergeladen und Abh√§ngigkeiten installiert
- [ ] API-Schl√ºssel konfiguriert (oder lokales Modell eingerichtet)
- [ ] Projektverzeichnis erstellt und strukturiert
- [ ] Eingabedateien vorbereitet und benannt
- [ ] Forschungsfrage formuliert
- [ ] Initiales Kategoriensystem entwickelt
- [ ] Kodierregeln definiert
- [ ] Konfiguration erstellt und validiert

#### Qualit√§tssicherung Checkliste

**W√§hrend der Analyse:**
- [ ] Pilotanalyse mit 10-20% der Daten durchgef√ºhrt
- [ ] Intercoder-Reliabilit√§t >0.6 erreicht
- [ ] Stichprobenkontrolle (10% manuell gepr√ºft)
- [ ] Kategorien bei Bedarf angepasst
- [ ] Fortschritt dokumentiert
- [ ] Zwischenergebnisse gesichert

**Nach der Analyse:**
- [ ] Vollst√§ndige Ergebnisse validiert
- [ ] Induktive Kategorien √ºberpr√ºft
- [ ] H√§ufigkeitsverteilungen plausibel
- [ ] Dokumentation vervollst√§ndigt
- [ ] Codebook finalisiert
- [ ] Ergebnisse exportiert und archiviert

#### Fehlerbehebung Checkliste

**Bei Problemen systematisch pr√ºfen:**
- [ ] Python-Version korrekt (3.10 oder 3.11)
- [ ] Alle Abh√§ngigkeiten installiert
- [ ] API-Schl√ºssel g√ºltig und verf√ºgbar
- [ ] Eingabedateien im korrekten Format
- [ ] Konfiguration syntaktisch korrekt
- [ ] Ausreichend Speicherplatz verf√ºgbar
- [ ] Internetverbindung stabil (f√ºr Cloud-Modelle)
- [ ] Firewall-Einstellungen korrekt

---

## Fazit und Ausblick

QCA-AID bietet Sozialwissenschaftler:innen ein m√§chtiges Werkzeug zur KI-unterst√ºtzten qualitativen Inhaltsanalyse. Die Kombination aus bew√§hrten methodischen Ans√§tzen und modernen KI-Technologien erm√∂glicht es, gr√∂√üere Datenmengen systematisch zu analysieren, ohne die Qualit√§tsstandards qualitativer Forschung zu vernachl√§ssigen.

### Wichtige Erfolgsfaktoren

1. **Methodische Fundierung:** QCA-AID ersetzt nicht die methodische Expertise, sondern erweitert sie
2. **Qualit√§tskontrolle:** Regelm√§√üige manuelle √úberpr√ºfung bleibt essentiell
3. **Iterative Entwicklung:** Kategorien und Regeln sollten kontinuierlich verfeinert werden
4. **Transparenz:** Vollst√§ndige Dokumentation aller Entscheidungen und Parameter
5. **Kritische Reflexion:** KI-Ergebnisse m√ºssen stets kritisch hinterfragt werden

### Weiterentwicklung

QCA-AID wird kontinuierlich weiterentwickelt. Aktuelle Entwicklungen und Updates finden Sie im [GitHub-Repository](https://github.com/JustusHenke/QCA-AID) und im [Changelog](CHANGELOG.md).

**Kontakt f√ºr Feedback und Fragen:**  
Justus Henke  
Institut f√ºr Hochschulforschung Halle-Wittenberg  
E-Mail: justus.henke@hof.uni-halle.de

---

**Viel Erfolg bei Ihrer qualitativen Forschung mit QCA-AID!** üöÄ
