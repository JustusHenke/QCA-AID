=== QCA-AID Console Log gestartet: 2025-11-17 22:31:15 ===
Log-Datei: C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\output\console_log_20251117_223115.txt
============================================================
=== Qualitative Inhaltsanalyse nach Mayring ===
Versuche Konfiguration zu laden von: C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA-AID-Codebook.xlsx

√ñffne Excel-Datei...
Excel-Datei erfolgreich geladen. Verf√ºgbare Sheets: ['FORSCHUNGSFRAGE', 'DEDUKTIVE_KATEGORIEN', 'KODIERREGELN', 'CONFIG']

Lese DEDUKTIVE_KATEGORIEN Sheet...

Kodierregeln geladen:
- Allgemeine Regeln: 5
- Formatregeln: 3
- Ausschlussregeln: 3
[CONFIG] EXPORT_ANNOTATED_PDFS geladen: True
[CONFIG] SIMILARITY_THRESHOLD geladen: 0.7
[CONFIG] ANALYSIS_MODE geladen: abductive
[CONFIG] REVIEW_MODE geladen: consensus
[SANITIZE] Ausgabeverzeichnis: C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\output
[SANITIZE] Verzeichnis: C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\input
[SANITIZE] Verzeichnis: C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\output
[SANITIZE] CHUNK_SIZE = 1000
[SANITIZE] CHUNK_OVERLAP = 40
[SANITIZE] CODE_WITH_CONTEXT = False
[SANITIZE] MULTIPLE_CODINGS = True
[SANITIZE] MULTIPLE_CODING_THRESHOLD = 0.85
[SANITIZE] BATCH_SIZE = 5

Starte Laden der deduktiven Kategorien...

Lade deduktive Kategorien...
Erfolgreich 8 Kategorien geladen

Kategorien erfolgreich in Config gespeichert

Konfiguration erfolgreich geladen
No existing revision history found - starting fresh

2. Lese Dokumente ein...

DocumentReader initialisiert:
Verzeichnis: C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\input
Unterst√ºtzte Formate: .txt, .pdf, .docx

Dateianalyse:

Gefundene Dateien:
[ERROR] .input-dir
[OK] dummy_solar_media.txt
[OK] text_demo_wiss.pdf
[OK] trial_case_iv_2.pdf

Verarbeite Dateien:

Lese: dummy_solar_media.txt
[OK] Erfolgreich eingelesen: 441 Zeichen

Lese: text_demo_wiss.pdf

Lese PDF: text_demo_wiss.pdf
  Gefundene Seiten: 1
  Seite 1/1: 4126 Zeichen extrahiert

Ergebnis:
  [OK] 1 Textabschnitte extrahiert
  [OK] Gesamtl√§nge: 4126 Zeichen
[OK] Erfolgreich eingelesen: 4126 Zeichen

Lese: trial_case_iv_2.pdf

Lese PDF: trial_case_iv_2.pdf
  Gefundene Seiten: 1
  Seite 1/1: 4320 Zeichen extrahiert

Ergebnis:
  [OK] 1 Textabschnitte extrahiert
  [OK] Gesamtl√§nge: 4320 Zeichen
[OK] Erfolgreich eingelesen: 4320 Zeichen

Verarbeitungsstatistik:
- Dateien im Verzeichnis: 4
- Unterst√ºtzte Dateien: 3
- Erfolgreich eingelesen: 3

3. Induktive Kodierung konfigurieren...

Gespeichertes induktives Codebook gefunden.
Automatische Fortf√úhrung in 10 Sekunden...

M√ñchten Sie das gespeicherte erweiterte Kodesystem laden? (j/N) (10s): 
M√ñchten Sie das gespeicherte erweiterte Kodesystem laden? (j/N) (9s): 
M√ñchten Sie das gespeicherte erweiterte Kodesystem laden? (j/N) (8s): 
M√ñchten Sie das gespeicherte erweiterte Kodesystem laden? (j/N) (7s): 

Aktueller Analysemodus aus Codebook: {default_mode}
Sie haben 10 Sekunden Zeit fuer die Eingabe.
Optionen:
1 = inductive (volle induktive Analyse)
2 = abductive (nur Subkategorien entwickeln)
3 = deductive (nur deduktiv)
4 = grounded (Subkategorien sammeln, spaeter Hauptkategorien generieren)

Welchen Analysemodus moechten Sie verwenden? [1/2/3/4] (Standard: abductive) (10s): 
Welchen Analysemodus moechten Sie verwenden? [1/2/3/4] (Standard: abductive) (9s): 
Welchen Analysemodus moechten Sie verwenden? [1/2/3/4] (Standard: abductive) (8s): 

Analysemodus: deductive (Skip induktiv)

4. Konfiguriere Kodierer...
üßæ Kodierer auto_1: 8 deduktive Kategorien geladen (deductive mode)
üîß Initialisiere LLM Provider: openai
‚úÖ OpenAI Client erfolgreich initialisiert
ü§ñ LLM Provider 'openai' fuer Kodierer auto_1 initialisiert
üßæ Kodierer auto_2: 8 deduktive Kategorien geladen (deductive mode)
üîß Initialisiere LLM Provider: openai
‚úÖ OpenAI Client erfolgreich initialisiert
ü§ñ LLM Provider 'openai' fuer Kodierer auto_2 initialisiert

Konfiguriere manuelle Kodierung...
Sie haben 10 Sekunden Zeit fuer die Eingabe.
Druecken Sie 'j' fuer manuelle Kodierung oder 'n' zum √úberspringen.

M√ñchten Sie manuell kodieren? (j/N) (10s): 
M√ñchten Sie manuell kodieren? (j/N) (9s): 
M√ñchten Sie manuell kodieren? (j/N) (8s): 

[INFO] Keine manuelle Kodierung - nur automatische Kodierung wird durchgef√úhrt

5. Bereite Material vor...

Chunking Ergebnis:
- Anzahl Chunks: 1
- Durchschnittliche Chunk-L√§nge: 441 Zeichen
- dummy_solar_media.txt: 1 Chunks erstellt

Chunking Ergebnis:
- Anzahl Chunks: 5
- Durchschnittliche Chunk-L√§nge: 831 Zeichen
- text_demo_wiss.pdf: 5 Chunks erstellt

Chunking Ergebnis:
- Anzahl Chunks: 5
- Durchschnittliche Chunk-L√§nge: 867 Zeichen
- trial_case_iv_2.pdf: 5 Chunks erstellt

7. Starte integrierte Analyse...

Kodierungsmodus: Mit progressivem Kontext
üîß Initialisiere LLM Provider: openai
‚úÖ OpenAI Client erfolgreich initialisiert

RelevanceChecker initialisiert:
- 0 Ausschlussregeln geladen

RelevanceChecker initialisiert:
- 0 Ausschlussregeln geladen
- Mehrfachkodierung: Aktiviert
- Mehrfachkodierung-Schwellenwert: 0.85
üîß Initialisiere LLM Provider: openai
‚úÖ OpenAI Client erfolgreich initialisiert

√∞≈∏‚Äù¬¨ Induktive Kodierung initialisiert:
- Min. Batches vor S√Ñttigung: 5
- Min. Materialabdeckung: 80%
- Stabilit√Ñtsschwelle: 3 Batches
üßæ Kodierer auto_1: 8 deduktive Kategorien geladen (deductive mode)
üîß Initialisiere LLM Provider: openai
‚úÖ OpenAI Client erfolgreich initialisiert
ü§ñ LLM Provider 'openai' fuer Kodierer auto_1 initialisiert
üßæ Kodierer auto_2: 8 deduktive Kategorien geladen (deductive mode)
üîß Initialisiere LLM Provider: openai
‚úÖ OpenAI Client erfolgreich initialisiert
ü§ñ LLM Provider 'openai' fuer Kodierer auto_2 initialisiert

Kontextuelle Kodierung: Aktiviert

√∞≈∏‚Äù¬¨ IntegratedAnalysisManager initialisiert:
   - Analysemodus: deductive
[OK] Session statistics reset

[TIP] Tipp: Druecken Sie ESC um die Kodierung sicher zu unterbrechen und Zwischenergebnisse zu speichern

Analyse gestartet um 22:31:25
Verarbeite 11 Segmente mit Batch-Gr√ñ·∫ûe 5...
Verarbeite 11 Segmente mit Batch-Gr√ñ·∫ûe 5...

============================================================
üßæ BATCH 1: 5 Segmente
‚ÑπÔ∏è Material verarbeitet: 0.0%
============================================================

üïµÔ∏è Schritt 1: Erweiterte Relevanzpr√úfung fuer Forschungsfrage...
[REVIEW] Erweiterte Relevanzpruefung mit Kategorie-Vorauswahl fuer 5 Segmente...

--- Analysefortschritt ---
Verarbeitet: 0 Segmente
Geschwindigkeit: 0.0 Segmente/Stunde
------------------------
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei erweiterter Relevanzpr√ºfung: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[SEARCH] Relevanzpruefung: 5 neue Segmente
   üì¶ Verwende normale Batch-Methode f√ºr 5 Segmente
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei paralleler Relevanzpr√ºfung: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[22:31:26] Traceback (most recent call last):
[22:31:26]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\relevance_checker.py", line 278, in check_relevance_batch
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:26]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:26]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:26]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:26]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:26] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
üßæ Erweiterte Relevanz: 5 von 5 Segmenten relevant
üéØ Kategorie-Pr√Ñferenzen: {}

üìù N√Ñchster Schritt: Deduktive Kodierung aller 5 Segmente...
üéØ Kontext-Kodierung: 5 Segmente haben Kategorie-Pr√Ñferenzen
[SEARCH] Relevanzpruefung: 5 neue Segmente
   üì¶ Verwende normale Batch-Methode f√ºr 5 Segmente
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei paralleler Relevanzpr√ºfung: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[22:31:26] Traceback (most recent call last):
[22:31:26]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\relevance_checker.py", line 278, in check_relevance_batch
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:26]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:26]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:26]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:26]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:26] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  ‚ÑπÔ∏è Pr√úfe 5 relevante Segmente auf Mehrfachkodierung...
[LAUNCH] Parallele Mehrfachkodierungs-Pruefung: 5 Segmente
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[WARN] Fehler bei Mehrfachkodierungs-Pruefung text_demo_wiss.pdf_chunk_3: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[WARN] Fehler bei Mehrfachkodierungs-Pruefung dummy_solar_media.txt_chunk_0: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[WARN] Fehler bei Mehrfachkodierungs-Pruefung text_demo_wiss.pdf_chunk_1: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[WARN] Fehler bei Mehrfachkodierungs-Pruefung text_demo_wiss.pdf_chunk_2: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[WARN] Fehler bei Mehrfachkodierungs-Pruefung text_demo_wiss.pdf_chunk_0: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ö° 5 Mehrfachkodierungs-Pr√ºfungen in 0.61s
üîÑ 0 Segmente mit Mehrfachkodierung identifiziert

üïµÔ∏è Verarbeite Segment dummy_solar_media.txt_chunk_0 mit Kontext
[SEARCH] Relevanzpruefung: 1 neue Segmente
   üì¶ Verwende normale Batch-Methode f√ºr 1 Segmente
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei paralleler Relevanzpr√ºfung: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[22:31:28] Traceback (most recent call last):
[22:31:28]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\relevance_checker.py", line 278, in check_relevance_batch
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:28]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:28]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:28]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:28]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:28] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}

Deduktiver Kodierer ü§ñ **auto_1** verarbeitet Chunk mit progressivem Kontext...
Dokumentfortschritt: ca. 0.0%
Summary-Reifephase: PHASE 1 (Sammlung), max. √Ñnderung: 50%
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei der Kodierung durch auto_1: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Details:
[22:31:28] Traceback (most recent call last):
[22:31:28]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\deductive_coding.py", line 571, in code_chunk_with_progressive_context
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:28]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:28]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:28]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:28]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:28] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  √¢≈°¬† Keine Kodierung von auto_1 erhalten

Deduktiver Kodierer ü§ñ **auto_2** verarbeitet Chunk mit progressivem Kontext...
Dokumentfortschritt: ca. 0.0%
Summary-Reifephase: PHASE 1 (Sammlung), max. √Ñnderung: 50%
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei der Kodierung durch auto_2: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Details:
[22:31:28] Traceback (most recent call last):
[22:31:28]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\deductive_coding.py", line 571, in code_chunk_with_progressive_context
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:28]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:28]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:28]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:28]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:28] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  √¢≈°¬† Keine Kodierung von auto_2 erhalten

üïµÔ∏è Verarbeite Segment text_demo_wiss.pdf_chunk_0 mit Kontext
[SEARCH] Relevanzpruefung: 1 neue Segmente
   üì¶ Verwende normale Batch-Methode f√ºr 1 Segmente
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei paralleler Relevanzpr√ºfung: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[22:31:29] Traceback (most recent call last):
[22:31:29]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\relevance_checker.py", line 278, in check_relevance_batch
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:29]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:29]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:29]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:29]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:29] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}

Deduktiver Kodierer ü§ñ **auto_1** verarbeitet Chunk mit progressivem Kontext...
Dokumentfortschritt: ca. 0.0%
Summary-Reifephase: PHASE 1 (Sammlung), max. √Ñnderung: 50%
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei der Kodierung durch auto_1: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Details:
[22:31:29] Traceback (most recent call last):
[22:31:29]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\deductive_coding.py", line 571, in code_chunk_with_progressive_context
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:29]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:29]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:29]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:29]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:29] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  √¢≈°¬† Keine Kodierung von auto_1 erhalten

Deduktiver Kodierer ü§ñ **auto_2** verarbeitet Chunk mit progressivem Kontext...
Dokumentfortschritt: ca. 0.0%
Summary-Reifephase: PHASE 1 (Sammlung), max. √Ñnderung: 50%
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei der Kodierung durch auto_2: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Details:
[22:31:29] Traceback (most recent call last):
[22:31:29]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\deductive_coding.py", line 571, in code_chunk_with_progressive_context
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:29]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:29]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:29]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:29]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:29] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  √¢≈°¬† Keine Kodierung von auto_2 erhalten

üïµÔ∏è Verarbeite Segment text_demo_wiss.pdf_chunk_1 mit Kontext
[SEARCH] Relevanzpruefung: 1 neue Segmente
   üì¶ Verwende normale Batch-Methode f√ºr 1 Segmente
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei paralleler Relevanzpr√ºfung: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[22:31:30] Traceback (most recent call last):
[22:31:30]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\relevance_checker.py", line 278, in check_relevance_batch
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:30]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:30]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:30]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:30]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:30] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}

Deduktiver Kodierer ü§ñ **auto_1** verarbeitet Chunk mit progressivem Kontext...
Dokumentfortschritt: ca. 5.0%
Summary-Reifephase: PHASE 1 (Sammlung), max. √Ñnderung: 50%
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei der Kodierung durch auto_1: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Details:
[22:31:30] Traceback (most recent call last):
[22:31:30]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\deductive_coding.py", line 571, in code_chunk_with_progressive_context
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:30]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:30]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:30]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:30]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:30] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  √¢≈°¬† Keine Kodierung von auto_1 erhalten

Deduktiver Kodierer ü§ñ **auto_2** verarbeitet Chunk mit progressivem Kontext...
Dokumentfortschritt: ca. 5.0%
Summary-Reifephase: PHASE 1 (Sammlung), max. √Ñnderung: 50%
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei der Kodierung durch auto_2: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Details:
[22:31:30] Traceback (most recent call last):
[22:31:30]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\deductive_coding.py", line 571, in code_chunk_with_progressive_context
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:30]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:30]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:30]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:30]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:30] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  √¢≈°¬† Keine Kodierung von auto_2 erhalten

üïµÔ∏è Verarbeite Segment text_demo_wiss.pdf_chunk_2 mit Kontext
[SEARCH] Relevanzpruefung: 1 neue Segmente
   üì¶ Verwende normale Batch-Methode f√ºr 1 Segmente
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei paralleler Relevanzpr√ºfung: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[22:31:30] Traceback (most recent call last):
[22:31:30]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\relevance_checker.py", line 278, in check_relevance_batch
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:30]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:30]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:30]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:30]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:30] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}

Deduktiver Kodierer ü§ñ **auto_1** verarbeitet Chunk mit progressivem Kontext...
Dokumentfortschritt: ca. 10.0%
Summary-Reifephase: PHASE 1 (Sammlung), max. √Ñnderung: 50%
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei der Kodierung durch auto_1: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Details:
[22:31:30] Traceback (most recent call last):
[22:31:30]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\deductive_coding.py", line 571, in code_chunk_with_progressive_context
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:30]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:30]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:30]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:30]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:30] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  √¢≈°¬† Keine Kodierung von auto_1 erhalten

Deduktiver Kodierer ü§ñ **auto_2** verarbeitet Chunk mit progressivem Kontext...
Dokumentfortschritt: ca. 10.0%
Summary-Reifephase: PHASE 1 (Sammlung), max. √Ñnderung: 50%
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei der Kodierung durch auto_2: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Details:
[22:31:31] Traceback (most recent call last):
[22:31:31]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\deductive_coding.py", line 571, in code_chunk_with_progressive_context
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:31]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:31]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:31]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:31]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:31] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  √¢≈°¬† Keine Kodierung von auto_2 erhalten

üïµÔ∏è Verarbeite Segment text_demo_wiss.pdf_chunk_3 mit Kontext
[SEARCH] Relevanzpruefung: 1 neue Segmente
   üì¶ Verwende normale Batch-Methode f√ºr 1 Segmente
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei paralleler Relevanzpr√ºfung: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[22:31:31] Traceback (most recent call last):
[22:31:31]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\relevance_checker.py", line 278, in check_relevance_batch
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:31]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:31]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:31]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:31]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:31] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}

Deduktiver Kodierer ü§ñ **auto_1** verarbeitet Chunk mit progressivem Kontext...
Dokumentfortschritt: ca. 15.0%
Summary-Reifephase: PHASE 1 (Sammlung), max. √Ñnderung: 50%
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei der Kodierung durch auto_1: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Details:
[22:31:31] Traceback (most recent call last):
[22:31:31]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\deductive_coding.py", line 571, in code_chunk_with_progressive_context
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:31]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:31]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:31]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:31]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:31] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  √¢≈°¬† Keine Kodierung von auto_1 erhalten

Deduktiver Kodierer ü§ñ **auto_2** verarbeitet Chunk mit progressivem Kontext...
Dokumentfortschritt: ca. 15.0%
Summary-Reifephase: PHASE 1 (Sammlung), max. √Ñnderung: 50%
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei der Kodierung durch auto_2: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Details:
[22:31:31] Traceback (most recent call last):
[22:31:31]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\deductive_coding.py", line 571, in code_chunk_with_progressive_context
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:31]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:31]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:31]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:31]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:31] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  √¢≈°¬† Keine Kodierung von auto_2 erhalten

üßæ S√Ñttigungsstatus:
   [TARGET] Theoretische S√Ñttigung: 53.6%
   ‚ÑπÔ∏è Materialabdeckung: 45.5%

‚ÑπÔ∏è Fortschritt:
   - Verarbeitete Segmente: 5/11
   - Aktuelle Kategorien: 8
   - Kodierungen: 0
   - Batch-Zeit: 6.39s

============================================================
üßæ BATCH 2: 5 Segmente
‚ÑπÔ∏è Material verarbeitet: 45.5%
============================================================

üïµÔ∏è Schritt 1: Erweiterte Relevanzpr√úfung fuer Forschungsfrage...
[REVIEW] Erweiterte Relevanzpruefung mit Kategorie-Vorauswahl fuer 5 Segmente...
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei erweiterter Relevanzpr√ºfung: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[SEARCH] Relevanzpruefung: 5 neue Segmente
   üì¶ Verwende normale Batch-Methode f√ºr 5 Segmente
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei paralleler Relevanzpr√ºfung: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[22:31:32] Traceback (most recent call last):
[22:31:32]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\relevance_checker.py", line 278, in check_relevance_batch
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:32]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:32]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:32]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:32]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:32] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
üßæ Erweiterte Relevanz: 5 von 5 Segmenten relevant
üéØ Kategorie-Pr√Ñferenzen: {}

üìù N√Ñchster Schritt: Deduktive Kodierung aller 5 Segmente...
üéØ Kontext-Kodierung: 5 Segmente haben Kategorie-Pr√Ñferenzen
[SEARCH] Relevanzpruefung: 5 neue Segmente
   üì¶ Verwende normale Batch-Methode f√ºr 5 Segmente
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei paralleler Relevanzpr√ºfung: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[22:31:32] Traceback (most recent call last):
[22:31:32]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\relevance_checker.py", line 278, in check_relevance_batch
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:32]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:32]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:32]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:32]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:32] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  ‚ÑπÔ∏è Pr√úfe 5 relevante Segmente auf Mehrfachkodierung...
[LAUNCH] Parallele Mehrfachkodierungs-Pruefung: 5 Segmente
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[WARN] Fehler bei Mehrfachkodierungs-Pruefung trial_case_iv_2.pdf_chunk_0: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[WARN] Fehler bei Mehrfachkodierungs-Pruefung trial_case_iv_2.pdf_chunk_3: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[WARN] Fehler bei Mehrfachkodierungs-Pruefung text_demo_wiss.pdf_chunk_4: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[WARN] Fehler bei Mehrfachkodierungs-Pruefung trial_case_iv_2.pdf_chunk_1: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[WARN] Fehler bei Mehrfachkodierungs-Pruefung trial_case_iv_2.pdf_chunk_2: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ö° 5 Mehrfachkodierungs-Pr√ºfungen in 0.26s
üîÑ 0 Segmente mit Mehrfachkodierung identifiziert

üïµÔ∏è Verarbeite Segment text_demo_wiss.pdf_chunk_4 mit Kontext
[SEARCH] Relevanzpruefung: 1 neue Segmente
   üì¶ Verwende normale Batch-Methode f√ºr 1 Segmente
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei paralleler Relevanzpr√ºfung: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[22:31:32] Traceback (most recent call last):
[22:31:32]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\relevance_checker.py", line 278, in check_relevance_batch
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:32]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:32]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:32]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:32]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:32] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}

Deduktiver Kodierer ü§ñ **auto_1** verarbeitet Chunk mit progressivem Kontext...
Dokumentfortschritt: ca. 20.0%
Summary-Reifephase: PHASE 1 (Sammlung), max. √Ñnderung: 50%
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei der Kodierung durch auto_1: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Details:
[22:31:33] Traceback (most recent call last):
[22:31:33]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\deductive_coding.py", line 571, in code_chunk_with_progressive_context
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:33]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:33]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:33]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:33]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:33] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  √¢≈°¬† Keine Kodierung von auto_1 erhalten

Deduktiver Kodierer ü§ñ **auto_2** verarbeitet Chunk mit progressivem Kontext...
Dokumentfortschritt: ca. 20.0%
Summary-Reifephase: PHASE 1 (Sammlung), max. √Ñnderung: 50%
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei der Kodierung durch auto_2: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Details:
[22:31:33] Traceback (most recent call last):
[22:31:33]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\deductive_coding.py", line 571, in code_chunk_with_progressive_context
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:33]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:33]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:33]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:33]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:33] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  √¢≈°¬† Keine Kodierung von auto_2 erhalten

üïµÔ∏è Verarbeite Segment trial_case_iv_2.pdf_chunk_0 mit Kontext
[SEARCH] Relevanzpruefung: 1 neue Segmente
   üì¶ Verwende normale Batch-Methode f√ºr 1 Segmente
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei paralleler Relevanzpr√ºfung: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[22:31:33] Traceback (most recent call last):
[22:31:33]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\relevance_checker.py", line 278, in check_relevance_batch
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:33]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:33]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:33]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:33]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:33] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}

Deduktiver Kodierer ü§ñ **auto_1** verarbeitet Chunk mit progressivem Kontext...
Dokumentfortschritt: ca. 0.0%
Summary-Reifephase: PHASE 1 (Sammlung), max. √Ñnderung: 50%
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei der Kodierung durch auto_1: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Details:
[22:31:33] Traceback (most recent call last):
[22:31:33]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\deductive_coding.py", line 571, in code_chunk_with_progressive_context
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:33]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:33]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:33]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:33]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:33] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  √¢≈°¬† Keine Kodierung von auto_1 erhalten

Deduktiver Kodierer ü§ñ **auto_2** verarbeitet Chunk mit progressivem Kontext...
Dokumentfortschritt: ca. 0.0%
Summary-Reifephase: PHASE 1 (Sammlung), max. √Ñnderung: 50%
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei der Kodierung durch auto_2: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Details:
[22:31:33] Traceback (most recent call last):
[22:31:33]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\deductive_coding.py", line 571, in code_chunk_with_progressive_context
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:33]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:33]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:33]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:33]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:33] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  √¢≈°¬† Keine Kodierung von auto_2 erhalten

üïµÔ∏è Verarbeite Segment trial_case_iv_2.pdf_chunk_1 mit Kontext
[SEARCH] Relevanzpruefung: 1 neue Segmente
   üì¶ Verwende normale Batch-Methode f√ºr 1 Segmente
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei paralleler Relevanzpr√ºfung: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[22:31:34] Traceback (most recent call last):
[22:31:34]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\relevance_checker.py", line 278, in check_relevance_batch
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:34]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:34]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:34]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:34]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:34] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}

Deduktiver Kodierer ü§ñ **auto_1** verarbeitet Chunk mit progressivem Kontext...
Dokumentfortschritt: ca. 5.0%
Summary-Reifephase: PHASE 1 (Sammlung), max. √Ñnderung: 50%
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei der Kodierung durch auto_1: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Details:
[22:31:34] Traceback (most recent call last):
[22:31:34]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\deductive_coding.py", line 571, in code_chunk_with_progressive_context
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:34]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:34]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:34]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:34]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:34] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  √¢≈°¬† Keine Kodierung von auto_1 erhalten

Deduktiver Kodierer ü§ñ **auto_2** verarbeitet Chunk mit progressivem Kontext...
Dokumentfortschritt: ca. 5.0%
Summary-Reifephase: PHASE 1 (Sammlung), max. √Ñnderung: 50%
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei der Kodierung durch auto_2: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Details:
[22:31:34] Traceback (most recent call last):
[22:31:34]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\deductive_coding.py", line 571, in code_chunk_with_progressive_context
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:34]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:34]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:34]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:34]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:34] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  √¢≈°¬† Keine Kodierung von auto_2 erhalten

üïµÔ∏è Verarbeite Segment trial_case_iv_2.pdf_chunk_2 mit Kontext
[SEARCH] Relevanzpruefung: 1 neue Segmente
   üì¶ Verwende normale Batch-Methode f√ºr 1 Segmente
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei paralleler Relevanzpr√ºfung: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[22:31:34] Traceback (most recent call last):
[22:31:34]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\relevance_checker.py", line 278, in check_relevance_batch
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:34]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:34]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:34]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:34]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:34] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}

Deduktiver Kodierer ü§ñ **auto_1** verarbeitet Chunk mit progressivem Kontext...
Dokumentfortschritt: ca. 10.0%
Summary-Reifephase: PHASE 1 (Sammlung), max. √Ñnderung: 50%
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei der Kodierung durch auto_1: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Details:
[22:31:34] Traceback (most recent call last):
[22:31:34]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\deductive_coding.py", line 571, in code_chunk_with_progressive_context
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:34]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:34]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:34]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:34]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:34] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  √¢≈°¬† Keine Kodierung von auto_1 erhalten

Deduktiver Kodierer ü§ñ **auto_2** verarbeitet Chunk mit progressivem Kontext...
Dokumentfortschritt: ca. 10.0%
Summary-Reifephase: PHASE 1 (Sammlung), max. √Ñnderung: 50%
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei der Kodierung durch auto_2: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Details:
[22:31:35] Traceback (most recent call last):
[22:31:35]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\deductive_coding.py", line 571, in code_chunk_with_progressive_context
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:35]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:35]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:35]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:35]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:35] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  √¢≈°¬† Keine Kodierung von auto_2 erhalten

üïµÔ∏è Verarbeite Segment trial_case_iv_2.pdf_chunk_3 mit Kontext
[SEARCH] Relevanzpruefung: 1 neue Segmente
   üì¶ Verwende normale Batch-Methode f√ºr 1 Segmente
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei paralleler Relevanzpr√ºfung: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[22:31:35] Traceback (most recent call last):
[22:31:35]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\relevance_checker.py", line 278, in check_relevance_batch
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:35]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:35]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:35]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:35]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:35] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}

Deduktiver Kodierer ü§ñ **auto_1** verarbeitet Chunk mit progressivem Kontext...
Dokumentfortschritt: ca. 15.0%
Summary-Reifephase: PHASE 1 (Sammlung), max. √Ñnderung: 50%
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei der Kodierung durch auto_1: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Details:
[22:31:35] Traceback (most recent call last):
[22:31:35]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\deductive_coding.py", line 571, in code_chunk_with_progressive_context
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:35]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:35]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:35]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:35]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:35] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  √¢≈°¬† Keine Kodierung von auto_1 erhalten

Deduktiver Kodierer ü§ñ **auto_2** verarbeitet Chunk mit progressivem Kontext...
Dokumentfortschritt: ca. 15.0%
Summary-Reifephase: PHASE 1 (Sammlung), max. √Ñnderung: 50%
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei der Kodierung durch auto_2: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Details:
[22:31:35] Traceback (most recent call last):
[22:31:35]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\deductive_coding.py", line 571, in code_chunk_with_progressive_context
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:35]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:35]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:35]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:35]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:35] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  √¢≈°¬† Keine Kodierung von auto_2 erhalten

üßæ S√Ñttigungsstatus:
   [TARGET] Theoretische S√Ñttigung: 53.6%
   ‚ÑπÔ∏è Materialabdeckung: 90.9%

‚ÑπÔ∏è Fortschritt:
   - Verarbeitete Segmente: 10/11
   - Aktuelle Kategorien: 8
   - Kodierungen: 0
   - Batch-Zeit: 4.09s

============================================================
üßæ BATCH 3: 1 Segmente
‚ÑπÔ∏è Material verarbeitet: 90.9%
============================================================

üïµÔ∏è Schritt 1: Erweiterte Relevanzpr√úfung fuer Forschungsfrage...
[REVIEW] Erweiterte Relevanzpruefung mit Kategorie-Vorauswahl fuer 1 Segmente...
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei erweiterter Relevanzpr√ºfung: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[SEARCH] Relevanzpruefung: 1 neue Segmente
   üì¶ Verwende normale Batch-Methode f√ºr 1 Segmente
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei paralleler Relevanzpr√ºfung: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[22:31:36] Traceback (most recent call last):
[22:31:36]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\relevance_checker.py", line 278, in check_relevance_batch
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:36]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:36]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:36]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:36]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:36] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
üßæ Erweiterte Relevanz: 1 von 1 Segmenten relevant
üéØ Kategorie-Pr√Ñferenzen: {}

üìù N√Ñchster Schritt: Deduktive Kodierung aller 1 Segmente...
üéØ Kontext-Kodierung: 1 Segmente haben Kategorie-Pr√Ñferenzen
[SEARCH] Relevanzpruefung: 1 neue Segmente
   üì¶ Verwende normale Batch-Methode f√ºr 1 Segmente
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei paralleler Relevanzpr√ºfung: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[22:31:36] Traceback (most recent call last):
[22:31:36]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\relevance_checker.py", line 278, in check_relevance_batch
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:36]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:36]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:36]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:36]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:36] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  ‚ÑπÔ∏è Pr√úfe 1 relevante Segmente auf Mehrfachkodierung...
[LAUNCH] Parallele Mehrfachkodierungs-Pruefung: 1 Segmente
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[WARN] Fehler bei Mehrfachkodierungs-Pruefung trial_case_iv_2.pdf_chunk_4: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ö° 1 Mehrfachkodierungs-Pr√ºfungen in 0.17s
üîÑ 0 Segmente mit Mehrfachkodierung identifiziert

üïµÔ∏è Verarbeite Segment trial_case_iv_2.pdf_chunk_4 mit Kontext
[SEARCH] Relevanzpruefung: 1 neue Segmente
   üì¶ Verwende normale Batch-Methode f√ºr 1 Segmente
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei paralleler Relevanzpr√ºfung: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
[22:31:36] Traceback (most recent call last):
[22:31:36]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\relevance_checker.py", line 278, in check_relevance_batch
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:36]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:36]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:36]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:36]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:36] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}

Deduktiver Kodierer ü§ñ **auto_1** verarbeitet Chunk mit progressivem Kontext...
Dokumentfortschritt: ca. 20.0%
Summary-Reifephase: PHASE 1 (Sammlung), max. √Ñnderung: 50%
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei der Kodierung durch auto_1: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Details:
[22:31:36] Traceback (most recent call last):
[22:31:36]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\deductive_coding.py", line 571, in code_chunk_with_progressive_context
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:36]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:36]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:36]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:36]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:36] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  √¢≈°¬† Keine Kodierung von auto_1 erhalten

Deduktiver Kodierer ü§ñ **auto_2** verarbeitet Chunk mit progressivem Kontext...
Dokumentfortschritt: ca. 20.0%
Summary-Reifephase: PHASE 1 (Sammlung), max. √Ñnderung: 50%
‚ùå [ERROR] API-Fehler (nicht temperature-bezogen): Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
‚ùå [ERROR] Unerwarteter Fehler in create_completion: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Fehler bei der Kodierung durch auto_2: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
Details:
[22:31:37] Traceback (most recent call last):
[22:31:37]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\analysis\deductive_coding.py", line 571, in code_chunk_with_progressive_context
    response = await self.llm_provider.create_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:37]   File "C:\Users\justu\OneDrive\Projekte\Forschung\R-Projects\QCA-AID\QCA_AID_assets\utils\llm\openai_provider.py", line 127, in create_completion
    response = await self.client.chat.completions.create(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:37]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
[22:31:37]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[22:31:37]   File "C:\Users\justu\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\openai\_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None
[22:31:37] openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-40-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
  √¢≈°¬† Keine Kodierung von auto_2 erhalten

üßæ S√Ñttigungsstatus:
   [TARGET] Theoretische S√Ñttigung: 53.6%
   ‚ÑπÔ∏è Materialabdeckung: 100.0%

‚ÑπÔ∏è Fortschritt:
   - Verarbeitete Segmente: 11/11
   - Aktuelle Kategorien: 8
   - Kodierungen: 0
   - Batch-Zeit: 1.45s

üèÅ FINALISIERUNG (DEDUCTIVE MODE):

‚ÑπÔ∏è DEDUCTIVE MODE Finalisierung:
   - Kategorien: 8

================================================================================
üßæ KATEGORIENENTWICKLUNG ABGESCHLOSSEN
================================================================================
‚ÑπÔ∏è Entwicklungsbilanz:
   - Verarbeitete Batches: 3
   - Initial: 8 Kategorien
   - Neu entwickelt: 0 Kategorien
   - Final: 8 Kategorien
   - Subkategorien: 32

Fortschritts√úberwachung beendet.

Gesamtzahl Kodierungen: 0

Keine Kodierungen fuer Reliabilit√Ñtsberechnung

9. F√úhre kategorie-zentrierten Review-Prozess durch...
üîÄ‚Äπ Review-Modus: consensus
üìà Eingabe: 0 urspr√úngliche Kodierungen

=== REVIEW-PROZESS (CONSENSUS) ===
‚ÑπÔ∏è Erstelle kategorie-spezifische Segmente...
[OK] 0 kategorie-spezifische Segmente erstellt
üïµÔ∏è F√úhre Consensus-Review durch...
Review abgeschlossen: 0 finale Kodierungen
[OK] Review abgeschlossen: 0 finale Kodierungen
============================================================
=== QCA-AID Console Log beendet: 2025-11-17 22:31:37 ===
