"""
Induktive Kodierung fÃ¼r QCA-AID
================================
ErgÃ¤nzung deduktiver Kategorien durch induktive Kategorien mittels LLM.
"""

import json
from ..utils.tracking.token_tracker import TokenTracker, get_global_token_counter
from ..utils.llm.response import LLMResponse
from ..utils.llm.factory import LLMProviderFactory
import asyncio
from datetime import datetime
from typing import Dict, Optional, List, Set, Tuple, Any
from collections import defaultdict, Counter

from ..core.config import CONFIG, FORSCHUNGSFRAGE, KODIERREGELN
from ..core.data_models import CategoryDefinition, CodingResult
from ..QCA_Prompts import QCAPrompts, ConfidenceScales

# Verwende globale Token-Counter Instanz
token_counter = get_global_token_counter()


class InductiveCoder:
    """
    Vereinfachter induktiver Kodierer mit strikter 2-Phasen-Struktur:
    Phase 1: Kategoriensystem-Aufbau (mit strenger SÃ¤ttigung)
    Phase 2: Kodierung mit festem System
    """
    
    def __init__(self, model_name: str, temperature: float, output_dir: str, config: dict = None):
        self.model_name = model_name
        self.temperature = float(temperature)
        self.output_dir = output_dir
        self.config = config or CONFIG  # KORREKTUR: Speichere config
        
        # LLM Provider (unverÃ„ndert)
        provider_name = CONFIG.get('MODEL_PROVIDER', 'openai').lower()
        # Ãœbergebe model_name fÃ¼r Capability-Testing
        self.llm_provider = LLMProviderFactory.create_provider(provider_name, model_name=model_name)
        
        # Cache und Tracking (unverÃ„ndert)
        self.category_cache = {}
        self.analysis_cache = {}
        self.batch_results = []
        self.similarity_cache = {}
        
        # VERBESSERTE SÃ¤ttigungsschwellen (aus dem verbesserten Code)
        self.MIN_CONFIDENCE = 0.7
        self.MIN_EXAMPLES = 2
        self.MIN_CATEGORY_USAGE = 2
        self.MAX_CATEGORIES_PER_BATCH = 5
        
        # VERSCHÃ„RFTE SÃ¤ttigungskriterien (aus dem verbesserten Code)
        self.MIN_BATCHES_BEFORE_SATURATION = 5
        self.MIN_MATERIAL_COVERAGE = 0.8
        self.STABILITY_THRESHOLD = 3
        
        # Theoretische SÃ¤ttigungsmetriken (aus dem verbesserten Code)
        self.theoretical_saturation_history = []
        self.category_development_phases = []
        
        # Phasen-Management (unverÃ„ndert)
        self.current_phase = "development"
        self.categories_locked = False
        self.development_complete = False
        
        # SÃ¤ttigungs-Tracking (unverÃ„ndert)
        self.batches_without_new_categories = 0
        self.category_usage_history = {}
        self.rejected_categories = []
        
        # FÃœr Grounded Theory Modus (unverÃ„ndert)
        self.collected_subcodes = []
        self.segment_analyses = []

        self.discovered_aspects = set()
        self.batch_metrics = []
        
        # Prompt-Handler (unverÃ„ndert)
        self.prompt_handler = QCAPrompts(
            forschungsfrage=FORSCHUNGSFRAGE,
            kodierregeln=KODIERREGELN,
            deduktive_kategorien=CONFIG.get('DEDUKTIVE_KATEGORIEN', {})
        )


        # Show initialization message only for inductive mode
        analysis_mode = config.get('ANALYSIS_MODE', 'inductive') if config else CONFIG.get('ANALYSIS_MODE', 'inductive')
        if analysis_mode == 'inductive':
            print(f"\nðŸ§‘â€ðŸ’¼ Induktive Kodierung initialisiert:")
            print(f"- Min. Batches vor SÃ¤ttigung: {self.MIN_BATCHES_BEFORE_SATURATION}")
            print(f"- Min. Materialabdeckung: {self.MIN_MATERIAL_COVERAGE:.0%}")
            print(f"- StabilitÃ¤tsschwelle: {self.STABILITY_THRESHOLD} Batches")
        elif analysis_mode in ['abductive', 'grounded']:
            # Silent initialization for modes that may use inductive components
            pass
    
    
    
        
    def _create_proper_batches(self, segments: List[str], batch_size: int) -> List[List[str]]:
        """
        VERBESSERT: Erstellt Batches ohne kÃœnstliche GrÃ¶áºženreduzierung
        """
        if not segments:
            return []
        
        print(f"ðŸ”€Â¦ Erstelle Batches: {len(segments)} Segmente -> Batch-GrÃ¶áºže {batch_size}")
        
        batches = []
        for i in range(0, len(segments), batch_size):
            batch = segments[i:i + batch_size]
            batches.append(batch)
        
        print(f"ðŸ”€Â¦ Ergebnis: {len(batches)} gleichmÃ„áºžige Batches erstellt")
        return batches

    async def _validate_and_integrate_strict(self, candidates: Dict[str, CategoryDefinition], 
                                           existing: Dict[str, CategoryDefinition]) -> Dict[str, CategoryDefinition]:
        """
        Validierung und automatische Konsolidierung neuer Kategorien
        """
        # âœ… BUGFIX: Filtere None/ungÃ¼ltige Kandidaten
        valid_candidates = {
            name: category for name, category in candidates.items()
            if category is not None and hasattr(category, 'definition')
        }
        
        if not valid_candidates:
            print(f"âš ï¸ Keine gÃ¼ltigen Kandidaten (von {len(candidates)} eingegangen)")
            return {}
        
        validated = {}
        
        for name, category in valid_candidates.items():
            # 1. Ã„hnlichkeitsprÃœfung
            similar_existing = self._find_similar_category(category, existing)
            if similar_existing:
                print(f"â„¹ï¸ '{name}' zu Ã„hnlich zu '{similar_existing}' - wird konsolidiert")
                # Automatische Konsolidierung statt Ablehnung
                consolidated = await self._auto_merge_categories(
                    category, existing[similar_existing], name, similar_existing
                )
                if consolidated:
                    existing[similar_existing] = consolidated
                    # WICHTIG: Nutzung fuer konsolidierte Kategorie erhÃ–hen
                    self.category_usage_history[similar_existing] = self.category_usage_history.get(similar_existing, 0) + 1
                continue
            
            # 2. QualitÃ„tsprÃœfung
            if await self._meets_quality_standards(category):
                validated[name] = category
                # WICHTIG: Nutzung fuer neue Kategorie setzen
                self.category_usage_history[name] = self.category_usage_history.get(name, 0) + 1
                print(f"âœ… '{name}' validiert (Nutzung: {self.category_usage_history[name]})")
            else:
                print(f"âš ï¸ '{name}' erfÃœllt QualitÃ„tsstandards nicht")
        
        return validated
    
    async def _consolidate_categories(self, categories: Dict[str, CategoryDefinition]) -> Dict[str, CategoryDefinition]:
        """
        Automatische Konsolidierung Ã„hnlicher Kategorien
        """
        print("\nâ„¹ï¸ Starte automatische Konsolidierung...")
        
        consolidated = categories.copy()
        merge_candidates = []
        
        # Finde Konsolidierungskandidaten
        category_names = list(consolidated.keys())
        for i in range(len(category_names)):
            for j in range(i + 1, len(category_names)):
                name1, name2 = category_names[i], category_names[j]
                if name1 in consolidated and name2 in consolidated:
                    similarity = self._calculate_category_similarity(
                        consolidated[name1], consolidated[name2]
                    )
                    if similarity > 0.7:  # similarity_threshold
                        merge_candidates.append((name1, name2, similarity))
        
        # Sortiere nach Ã„hnlichkeit
        merge_candidates.sort(key=lambda x: x[2], reverse=True)
        
        # FÃ¼hre Konsolidierungen durch
        for name1, name2, similarity in merge_candidates[:3]:  # Max 3 Merges pro Runde
            if name1 in consolidated and name2 in consolidated:
                print(f"Ã°Å¸â€â€” Konsolidiere '{name1}' + '{name2}' (Ã„hnlichkeit: {similarity:.2f})")
                merged = await self._merge_categories_intelligent(
                    consolidated[name1], consolidated[name2], name1, name2
                )
                if merged:
                    # Verwende den besseren Namen
                    better_name = self._choose_better_name(name1, name2)
                    consolidated[better_name] = merged
                    
                    # Entferne die anderen
                    other_name = name2 if better_name == name1 else name1
                    del consolidated[other_name]
                    
                    print(f"âœ… Konsolidiert zu '{better_name}'")
        
        return consolidated
    
    async def _finalize_categories(self, categories: Dict[str, CategoryDefinition]) -> Dict[str, CategoryDefinition]:
        """
        Finale Bereinigung des Kategoriensystems
        """
        print("\nÃ°Å¸Â§Â¹ Finale Bereinigung...")
        
        cleaned = {}
        
        for name, category in categories.items():
            # KORRIGIERT: Verwende deutlich niedrigere Schwelle oder Ãœberspringe Check
            usage_count = self.category_usage_history.get(name, 0)
            
            # TEMPORÃ„RER FIX: Akzeptiere alle Kategorien in der Entwicklungsphase
            if self.current_phase == "development":
                print(f"âœ… '{name}' Ãœbernommen (Entwicklungsphase)")
                cleaned[name] = category
                continue
                
            # KORRIGIERT: Viel niedrigere Schwelle
            min_usage = max(1, self.MIN_CATEGORY_USAGE // 3)  # 1 statt 3
            
            if usage_count >= min_usage:
                # Verbessere Definition falls nÃ–tig
                if len(category.definition.split()) < 20:
                    enhanced = await self._enhance_category_definition(category)
                    if enhanced:
                        category = category.replace(definition=enhanced.definition)
                
                cleaned[name] = category
                print(f"âœ… '{name}' Ãœbernommen (Nutzung: {usage_count})")
            else:
                print(f"âš ï¸ '{name}' entfernt (Zu wenig genutzt: {usage_count}, Mindest: {min_usage})")
        
        return cleaned
    
    def _update_usage_history(self, category_names: List[str]) -> None:
        """
        Aktualisiert die Nutzungshistorie fuer Kategorien
        """
        for name in category_names:
            if name in self.category_usage_history:
                self.category_usage_history[name] += 1
            else:
                self.category_usage_history[name] = 1
        
        print(f"ðŸ§¾ Nutzungshistorie aktualisiert fuer: {category_names}")
        print(f"    Aktuelle Nutzung: {dict(list(self.category_usage_history.items())[-3:])}")

    def _create_category_definition(self, cat_data: dict) -> CategoryDefinition:
        """
        Erstellt CategoryDefinition aus API-Response Dictionary
        """
        try:
            return CategoryDefinition(
                name=cat_data.get('name', ''),
                definition=cat_data.get('definition', ''),
                examples=cat_data.get('evidence', []),
                rules=[],  # Wird spaeter entwickelt
                subcategories={
                    sub.get('name', ''): sub.get('definition', '')
                    for sub in cat_data.get('subcategories', [])
                },
                added_date=datetime.now().strftime("%Y-%m-%d"),
                modified_date=datetime.now().strftime("%Y-%m-%d")
            )
        except Exception as e:
            print(f"Fehler bei CategoryDefinition-Erstellung: {str(e)}")
            return None
    
    
    
    def _format_existing_categories(self, categories: Dict[str, CategoryDefinition]) -> str:
        """Formatiert bestehende Kategorien fuer Prompt"""
        if not categories:
            return "Keine bestehenden Kategorien."
        
        formatted = []
        for name, cat in categories.items():
            definition_preview = cat.definition[:100] + "..." if len(cat.definition) > 100 else cat.definition
            formatted.append(f"- {name}: {definition_preview}")
        
        return "\n".join(formatted)

    
    async def develop_category_system(self, segments: List[str], initial_categories: Dict[str, CategoryDefinition] = None) -> Dict[str, CategoryDefinition]:
        """
        VERBESSERTE Kategorienentwicklung mit korrekter SÃ¤ttigungslogik
        """
        print(f"\nðŸ•µï¸ Starte verbesserte induktive Entwicklung mit {len(segments)} Segmenten")
        
        current_categories = initial_categories.copy() if initial_categories else {}
        analysis_mode = CONFIG.get('ANALYSIS_MODE', 'inductive')
        
        print(f"\nðŸ§¾ Analysemodus: {analysis_mode.upper()}")
        
        # Reset Tracking
        self.theoretical_saturation_history = []
        self.category_development_phases = []
        self.batches_without_new_categories = 0
        
        # VERBESSERTE Batch-Erstellung (keine kÃœnstliche Reduzierung)
        print("\nðŸ”€Â¦ Erstelle optimierte Batches...")

        # Erstelle Batches direkt
        effective_batch_size = min(CONFIG.get('BATCH_SIZE', 5), len(segments))
        batches = self._create_proper_batches(segments, effective_batch_size)
        
        
        print(f"ðŸ§¾ Batch-Konfiguration:")
        print(f"- Relevante Segmente: {len(segments)}")
        print(f"- Batch-GrÃ¶áºže: {effective_batch_size}")
        print(f"- Anzahl Batches: {len(batches)}")
        
        working_categories = current_categories.copy()
        
        # HAUPTSCHLEIFE mit verbesserter SÃ¤ttigungslogik
        for batch_idx, batch in enumerate(batches):
            print(f"\n{'='*60}")
            print(f"ðŸ§¾ BATCH {batch_idx + 1}/{len(batches)} - Kategorienentwicklung")
            print(f"{'='*60}")
            
            # Analysiere Batch
            new_candidates = await self._analyze_batch_improved(batch, working_categories, analysis_mode)
            
            # Validiere und integriere neue Kategorien
            if new_candidates:
                validated_categories = await self._validate_and_integrate_strict(new_candidates, working_categories)
                
                if validated_categories:
                    before_count = len(working_categories)
                    working_categories.update(validated_categories)
                    added_count = len(working_categories) - before_count
                    
                    print(f"âœ… {added_count} neue Kategorien integriert")
                    self.batches_without_new_categories = 0
                    self._update_usage_history(list(validated_categories.keys()))
                    
                    # Dokumentiere Entwicklungsphase
                    self.category_development_phases.append({
                        'batch': batch_idx + 1,
                        'new_categories': added_count,
                        'total_categories': len(working_categories),
                        'material_coverage': (batch_idx + 1) / len(batches)
                    })
                else:
                    print("âš ï¸ Keine Kategorien haben strenge Validierung bestanden")
                    self.batches_without_new_categories += 1
            else:
                print("â„¹ï¸ Keine neuen Kategorien in diesem Batch")
                self.batches_without_new_categories += 1
            
            # VERBESSERTE SÃ¤ttigungsprÃœfung
            saturation_metrics = self._assess_comprehensive_saturation(
                working_categories, 
                batch_idx + 1, 
                len(batches)
            )
            
            print(f"\nâ„¹ï¸ SÃ„TTIGUNGSANALYSE:")
            print(f"- Theoretische SÃ¤ttigung: {saturation_metrics['theoretical_saturation']:.2f}")
            print(f"- Materialabdeckung: {saturation_metrics['material_coverage']:.1%}")
            print(f"- Stabile Batches: {saturation_metrics['stable_batches']}")
            print(f"- KategorienqualitÃ¤t: {saturation_metrics['category_quality']:.2f}")
            print(f"- Di: {saturation_metrics['category_diversity']:.2f}")
            
            # Speichere SÃ¤ttigungshistorie
            self.theoretical_saturation_history.append(saturation_metrics)
            
            # PrÃ¼fe ALLE SÃ¤ttigungskriterien
            if self._check_comprehensive_saturation(saturation_metrics, batch_idx + 1, len(batches)):
                print(f"\nðŸ VOLLSTÃ„NDIGE SÃ„TTIGUNG erreicht nach Batch {batch_idx + 1}")
                print(f"ðŸ§¾ SÃ¤ttigungsgrund:")
                for criterion, value in saturation_metrics.items():
                    print(f"   - {criterion}: {value}")
                break
            else:
                print(f"\nâ„¹ï¸ SÃ¤ttigung noch nicht erreicht - fortsetzen")
                self._log_saturation_progress(saturation_metrics)
            
            # Zwischenkonsolidierung alle 3 Batches
            if (batch_idx + 1) % 3 == 0:
                print(f"\nâ„¹ï¸ Zwischenkonsolidierung nach Batch {batch_idx + 1}")
                working_categories = await self._consolidate_categories(working_categories)
        
        # Finale Bereinigung und QualitÃ„tssicherung
        final_categories = await self._finalize_categories(working_categories)
        
        # Zeige finale Entwicklungsstatistiken
        self._show_development_summary(final_categories, initial_categories)
        
        return final_categories

    def _create_proper_batches(self, segments: List[str], batch_size: int) -> List[List[str]]:
        """
        VERBESSERT: Erstellt Batches ohne kÃœnstliche GrÃ¶áºženreduzierung
        """
        if not segments:
            return []
        
        print(f"ðŸ”€Â¦ Erstelle Batches: {len(segments)} Segmente -> Batch-GrÃ¶áºže {batch_size}")
        
        batches = []
        for i in range(0, len(segments), batch_size):
            batch = segments[i:i + batch_size]
            batches.append(batch)
        
        print(f"ðŸ”€Â¦ Ergebnis: {len(batches)} gleichmÃ„áºžige Batches erstellt")
        return batches

    def _assess_comprehensive_saturation(self, categories: Dict[str, CategoryDefinition], 
                                       current_batch: int, total_batches: int) -> Dict[str, float]:
        """
        VERBESSERTE umfassende SÃ¤ttigungsbeurteilung
        """
        # 1. Theoretische SÃ¤ttigung (KategorienqualitÃ¤t und -vollstÃ¤ndigkeit)
        theoretical_saturation = self._calculate_theoretical_saturation(categories)
        
        # 2. Materialabdeckung
        material_coverage = current_batch / total_batches
        
        # 3. StabilitÃ„t (Batches ohne neue Kategorien)
        stability_ratio = self.batches_without_new_categories / max(1, current_batch)
        
        # 4. KategorienqualitÃ¤t (Definition, Beispiele, Subkategorien)
        category_quality = self._assess_category_quality(categories)
        
        # 5. Kategorien-Di (thematische Abdeckung)
        category_diversity = self._calculate_category_diversity(categories)
        
        return {
            'theoretical_saturation': theoretical_saturation,
            'material_coverage': material_coverage,
            'stable_batches': self.batches_without_new_categories,
            'stability_ratio': stability_ratio,
            'category_quality': category_quality,
            'category_diversity': category_diversity,
            'total_categories': len(categories)
        }

    def _calculate_theoretical_saturation(self, categories: Dict[str, CategoryDefinition]) -> float:
        """
        Berechnet theoretische SÃ¤ttigung basierend auf Kategorienreife und Forschungsabdeckung
        """
        if not categories:
            return 0.0
        
        # 1. Kategorienreife (Definition, Beispiele, Subkategorien)
        maturity_scores = []
        for cat in categories.values():
            score = 0
            # Definition (0-0.4)
            def_score = min(len(cat.definition.split()) / 30, 0.4)
            # Beispiele (0-0.3)
            example_score = min(len(cat.examples) / 5, 0.3)
            # Subkategorien (0-0.3)
            subcat_score = min(len(cat.subcategories) / 4, 0.3)
            
            total_score = def_score + example_score + subcat_score
            maturity_scores.append(total_score)
        
        avg_maturity = sum(maturity_scores) / len(maturity_scores)
        
        # 2. Forschungsabdeckung (Anzahl und Di der Kategorien)
        # SchÃ„tze optimale Kategorienanzahl basierend auf Forschungsfrage
        estimated_optimal = 8  # Typisch fuer qualitative Analysen
        coverage_ratio = min(len(categories) / estimated_optimal, 1.0)
        
        # 3. Kombinierte theoretische SÃ¤ttigung
        theoretical_saturation = (avg_maturity * 0.7) + (coverage_ratio * 0.3)
        
        return min(theoretical_saturation, 1.0)

    def _assess_category_quality(self, categories: Dict[str, CategoryDefinition]) -> float:
        """
        Bewertet die durchschnittliche QualitÃ„t aller Kategorien
        """
        if not categories:
            return 0.0
        
        quality_scores = []
        for cat in categories.values():
            score = 0
            
            # Definition ausreichend (0-0.4)
            if len(cat.definition.split()) >= 20:
                score += 0.4
            elif len(cat.definition.split()) >= 10:
                score += 0.2
            
            # Beispiele vorhanden (0-0.3)
            if len(cat.examples) >= 3:
                score += 0.3
            elif len(cat.examples) >= 1:
                score += 0.15
            
            # Subkategorien entwickelt (0-0.3)
            if len(cat.subcategories) >= 3:
                score += 0.3
            elif len(cat.subcategories) >= 1:
                score += 0.15
            
            quality_scores.append(score)
        
        return sum(quality_scores) / len(quality_scores)

    def _calculate_category_diversity(self, categories: Dict[str, CategoryDefinition]) -> float:
        """
        Berechnet thematische Di der Kategorien
        """
        if not categories:
            return 0.0
        
        # Sammle SchlÃœsselwÃ–rter aus allen Definitionen
        all_keywords = set()
        for cat in categories.values():
            words = cat.definition.lower().split()
            keywords = [w for w in words if len(w) > 4]  # Nur lÃ„ngere WÃ–rter
            all_keywords.update(keywords[:5])  # Top 5 pro Kategorie
        
        # Di = VerhÃ„ltnis von einzigartigen Begriffen zu Kategorien
        diversity = len(all_keywords) / (len(categories) * 3)  # Normalisiert
        return min(diversity, 1.0)

    def _check_comprehensive_saturation(self, saturation_metrics: Dict[str, float], 
                                      current_batch: int, total_batches: int) -> bool:
        """
        VERSCHÃ„RFTE SÃ¤ttigungsprÃœfung mit mehreren Kriterien
        """
        # Mindestkriterien
        min_batches = max(self.MIN_BATCHES_BEFORE_SATURATION, total_batches * 0.3)
        min_material = self.MIN_MATERIAL_COVERAGE
        min_stability = self.STABILITY_THRESHOLD
        
        # PrÃ¼fe alle Kriterien
        criteria_met = {
            'min_batches': current_batch >= min_batches,
            'material_coverage': saturation_metrics['material_coverage'] >= min_material,
            'theoretical_saturation': saturation_metrics['theoretical_saturation'] >= 0.8,
            'category_quality': saturation_metrics['category_quality'] >= 0.7,
            'stability': saturation_metrics['stable_batches'] >= min_stability,
            'sufficient_categories': saturation_metrics['total_categories'] >= 3
        }
        
        print(f"\nðŸ•µï¸ SÃ¤ttigungskriterien:")
        for criterion, met in criteria_met.items():
            status = "âœ…" if met else "âš ï¸"
            print(f"   {status} {criterion}: {met}")
        
        # SÃ¤ttigung nur wenn ALLE Kriterien erfÃœllt
        is_saturated = all(criteria_met.values())
        
        if is_saturated:
            print(f"\nðŸŽ¯ ALLE SÃ¤ttigungskriterien erfÃœllt!")
        else:
            missing = [k for k, v in criteria_met.items() if not v]
            print(f"\nâ„¹ï¸ Fehlende Kriterien: {', '.join(missing)}")
        
        return is_saturated

    def _create_inductive_mode_prompt(self, segments_text: str, existing_categories: Dict[str, CategoryDefinition]) -> str:
        """
        Erstellt spezifischen Prompt fuer INDUCTIVE MODE (vollstÃ¤ndige induktive Kategorienentwicklung)
        """
        # Formatiere bestehende induktive Kategorien als Kontext (aber nicht als EinschrÃ„nkung)
        existing_context = ""
        if existing_categories:
            existing_names = list(existing_categories.keys())
            existing_context = f"""
            BESTEHENDE INDUKTIVE KATEGORIEN (als Kontext, NICHT als EinschrÃ„nkung):
            {', '.join(existing_names)}
            
            WICHTIG: Entwickle NEUE, EIGENSTÃ„NDIGE Kategorien, die sich thematisch von den bestehenden unterscheiden.
            Beachte aber die bereits entwickelten Kategorien um Redundanzen zu vermeiden.
            """
        
        return f"""
        FORSCHUNGSFRAGE (ZENTRALE ORIENTIERUNG):
        {FORSCHUNGSFRAGE}

        INDUCTIVE MODE: VollstÃ¤ndige induktive Kategorienentwicklung

        {existing_context}

        WICHTIG - FORSCHUNGSFRAGE BERÃœCKSICHTIGEN:
        - PrÃ¼fe ZUERST, ob ein Textsegment zur Forschungsfrage relevant ist
        - Entwickle NUR Kategorien fÃ¼r Aspekte, die zur Beantwortung der Forschungsfrage beitragen
        - Kategoriennamen sollten Terminologie der Forschungsfrage aufgreifen, wo sinnvoll
        - Irrelevante textliche Details NICHT kategorisieren

        AUFGABE: Entwickle voellig NEUE Hauptkategorien aus den folgenden Textsegmenten.
        Dies ist ein eigenstÃ¤ndiges induktives Kategoriensystem, unabhÃ„ngig von deduktiven Kategorien.

        REGELN FÃœR INDUCTIVE MODE:
        - Entwickle 1-{self.MAX_CATEGORIES_PER_BATCH} NEUE Hauptkategorien
        - Jede Kategorie muss mindestens {self.MIN_EXAMPLES} Textbelege haben
        - Konfidenz mindestens {self.MIN_CONFIDENCE}
        - Kategorien mÃœssen thematisch eigenstÃ¤ndig und relevant fÃ¼r die Forschungsfrage sein
        - Erstelle auch 2-4 Subkategorien pro Hauptkategorie
        - Kategorien sollen neue Aspekte der Forschungsfrage beleuchten
        - Vermeide Redundanzen zu bereits entwickelten Kategorien

        TEXTSEGMENTE:
        {segments_text}

        Antworte NUR mit JSON:
        {{
            "new_categories": [
                {{
                    "name": "Kategorie Name",
                    "definition": "AusfÃœhrliche Definition (mindestens 20 WÃ–rter)",
                    "evidence": ["Textbelege aus den Segmenten"],
                    "confidence": 0.0-1.0,
                    "subcategories": [
                        {{
                            "name": "Subkategorie Name", 
                            "definition": "Subkategorie Definition"
                        }}
                    ],
                    "thematic_justification": "Warum diese Kategorie einen eigenstÃ¤ndigen Themenbereich abbildet und zur Forschungsfrage beitrÃ¤gt"
                }}
            ],
            "development_assessment": {{
                "categories_developed": 0,
                "theoretical_saturation": 0.0-1.0,
                "new_themes_found": true/false,
                "recommendation": "continue/pause/stop"
            }}
        }}
        """
    
    def _create_abductive_mode_prompt(self, segments_text: str, existing_categories: Dict[str, CategoryDefinition]) -> str:
        """
        Erstellt spezifischen Prompt fuer ABDUCTIVE MODE (nur Subkategorien)
        """
        categories_context = []
        for cat_name, cat_def in existing_categories.items():
            categories_context.append({
                'name': cat_name,
                'definition': cat_def.definition[:200],
                'existing_subcategories': list(cat_def.subcategories.keys())
            })

        return f"""
        ABDUKTIVER MODUS: Entwickle NUR neue Subkategorien fuer bestehende Hauptkategorien.

        BESTEHENDE HAUPTKATEGORIEN:
        {json.dumps(categories_context, indent=2, ensure_ascii=False)}

        STRIKTE REGELN FÃœR ABDUKTIVEN MODUS:
        - KEINE neuen Hauptkategorien entwickeln
        - NUR neue Subkategorien fuer bestehende Hauptkategorien
        - Subkategorien mÃœssen neue, relevante Themenaspekte abbilden
        - Mindestens {self.MIN_EXAMPLES} Textbelege pro Subkategorie
        - Konfidenz mindestens {self.MIN_CONFIDENCE}
        - PrÃ¼fe JEDE bestehende Hauptkategorie auf mÃ–gliche neue Subkategorien
        
        TEXTSEGMENTE:
        {segments_text}
        
        Antworte NUR mit JSON:
        {{
            "extended_categories": {{
                "hauptkategorie_name": {{
                    "new_subcategories": [
                        {{
                            "name": "Subkategorie Name",
                            "definition": "Definition der Subkategorie",
                            "evidence": ["Textbelege"],
                            "confidence": 0.0-1.0,
                            "thematic_novelty": "Warum diese Subkategorie einen neuen Aspekt abbildet"
                        }}
                    ]
                }}
            }},
            "saturation_assessment": {{
                "subcategory_saturation": 0.0-1.0,
                "new_aspects_found": true/false,
                "recommendation": "continue/pause/stop"
            }}
        }}
        """

    def _create_standard_prompt(self, segments_text: str, existing_categories: Dict[str, CategoryDefinition]) -> str:
        """
        Erstellt Standard-Prompt fuer allgemeine induktive Kategorienentwicklung
        """
        existing_context = ""
        if existing_categories:
            existing_names = list(existing_categories.keys())
            existing_context = f"Bestehende Kategorien: {', '.join(existing_names)}"

        return f"""
        FORSCHUNGSFRAGE (ZENTRALE ORIENTIERUNG):
        {FORSCHUNGSFRAGE}

        STANDARD INDUKTIVE KATEGORIENENTWICKLUNG

        {existing_context}

        WICHTIG - FORSCHUNGSFRAGE BERÃœCKSICHTIGEN:
        - PrÃ¼fe ZUERST, ob ein Textsegment zur Forschungsfrage relevant ist
        - Entwickle NUR Kategorien fÃ¼r Aspekte, die zur Beantwortung der Forschungsfrage beitragen
        - Kategoriennamen sollten Terminologie der Forschungsfrage aufgreifen, wo sinnvoll

        AUFGABE: Entwickle neue Kategorien aus den folgenden Textsegmenten.

        ALLGEMEINE REGELN:
        - Entwickle 1-{self.MAX_CATEGORIES_PER_BATCH} neue Kategorien
        - Jede Kategorie braucht mindestens {self.MIN_EXAMPLES} Textbelege
        - Konfidenz mindestens {self.MIN_CONFIDENCE}
        - Erstelle aussagekrÃ„ftige Definitionen, die den Bezug zur Forschungsfrage verdeutlichen
        - FÃ¼ge relevante Subkategorien hinzu

        TEXTSEGMENTE:
        {segments_text}

        Antworte NUR mit JSON:
        {{
            "new_categories": [
                {{
                    "name": "Kategorie Name",
                    "definition": "Kategorie Definition",
                    "evidence": ["Textbelege"],
                    "confidence": 0.0-1.0,
                    "subcategories": [
                        {{"name": "Subkategorie", "definition": "Definition"}}
                    ]
                }}
            ]
        }}
        """
    
    async def _analyze_batch_improved(self, batch: List[str], existing_categories: Dict[str, CategoryDefinition], analysis_mode: str) -> Dict[str, CategoryDefinition]:
        """
        VERBESSERTE Batch-Analyse mit modusabhÃ„ngiger Logik
        """
        segments_text = "\n\n=== SEGMENT BREAK ===\n\n".join(
            f"SEGMENT {i + 1}:\n{text}" 
            for i, text in enumerate(batch)
        )

        # ModusabhÃ„ngige Prompt-Erstellung
        if analysis_mode == 'inductive':
            prompt = self._create_inductive_mode_prompt(segments_text, existing_categories)
        elif analysis_mode == 'abductive':
            prompt = self._create_abductive_mode_prompt(segments_text, existing_categories)
        else:
            prompt = self._create_standard_prompt(segments_text, existing_categories)

        try:
            token_counter.start_request()
            
            response = await self.llm_provider.create_completion(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "Du bist ein Experte fuer qualitative Inhaltsanalyse. Antworte auf deutsch. Antworte ausschliesslich mit einem JSON-Objekt."},
                    {"role": "user", "content": prompt}
                ],
                temperature=self.temperature,
                response_format={"type": "json_object"}
            )
            
            llm_response = LLMResponse(response)
            result = json.loads(llm_response.extract_json())
            
            
            token_counter.track_response(response, self.model_name)
            
            # Verarbeite Ergebnisse
            candidates = {}
            
            for cat_data in result.get('new_categories', []):
                confidence = float(cat_data.get('confidence', 0))
                if confidence >= self.MIN_CONFIDENCE:
                    candidates[cat_data['name']] = self._create_category_definition(cat_data)
                    print(f"âœ… Neuer Kandidat: '{cat_data['name']}' (Konfidenz: {confidence:.2f})")
            
            return candidates
            
        except Exception as e:
            print(f"Fehler bei verbesserter Batch-Analyse: {str(e)}")
            return {}

    def _create_abductive_mode_prompt(self, segments_text: str, existing_categories: Dict[str, CategoryDefinition]) -> str:
        """
        Erstellt spezifischen Prompt fuer abduktiven Modus (nur Subkategorien)
        """
        categories_context = []
        for cat_name, cat_def in existing_categories.items():
            categories_context.append({
                'name': cat_name,
                'definition': cat_def.definition,
                'existing_subcategories': list(cat_def.subcategories.keys())
            })

        return f"""
        ABDUKTIVER MODUS: Entwickle NUR neue Subkategorien fuer bestehende Hauptkategorien.

        BESTEHENDE HAUPTKATEGORIEN:
        {json.dumps(categories_context, indent=2, ensure_ascii=False)}

        STRIKTE REGELN:
        - KEINE neuen Hauptkategorien entwickeln
        - NUR neue Subkategorien fuer bestehende Hauptkategorien
        - Subkategorien mÃœssen neue, relevante Themenaspekte abbilden
        - Mindestens {self.MIN_EXAMPLES} Textbelege pro Subkategorie
        - Konfidenz mindestens {self.MIN_CONFIDENCE}
        
        TEXTSEGMENTE:
        {segments_text}
        
        Antworte NUR mit JSON:
        {{
            "extended_categories": {{
                "hauptkategorie_name": {{
                    "new_subcategories": [
                        {{
                            "name": "Subkategorie Name",
                            "definition": "Definition der Subkategorie",
                            "evidence": ["Textbelege"],
                            "confidence": 0.0-1.0,
                            "thematic_novelty": "Warum diese Subkategorie einen neuen Aspekt abbildet"
                        }}
                    ]
                }}
            }},
            "saturation_assessment": {{
                "subcategory_saturation": 0.0-1.0,
                "new_aspects_found": true/false,
                "recommendation": "continue/pause/stop"
            }}
        }}
        """

    def _log_saturation_progress(self, saturation_metrics: Dict[str, float]) -> None:
        """
        Protokolliert SÃ¤ttigungsfortschritt fuer Benutzer-Feedback
        """
        print(f"\nðŸ§¾ SÃ¤ttigungsfortschritt:")
        print(f"   ðŸŽ¯ Theoretische SÃ¤ttigung: {saturation_metrics['theoretical_saturation']:.1%}")
        print(f"   â„¹ï¸ Materialabdeckung: {saturation_metrics['material_coverage']:.1%}")
        print(f"   â„¹ï¸ StabilitÃ„t: {saturation_metrics['stable_batches']} Batches ohne neue Kategorien")
        print(f"   Ã¢Â­Â KategorienqualitÃ¤t: {saturation_metrics['category_quality']:.1%}")
        print(f"   Ã°Å¸Å’Ë† Di: {saturation_metrics['category_diversity']:.1%}")

    def _show_development_summary(self, final_categories: Dict[str, CategoryDefinition], 
                                initial_categories: Dict[str, CategoryDefinition]) -> None:
        """
        Zeigt finale Entwicklungsstatistiken
        """
        print(f"\n{'='*60}")
        print(f"ðŸ§¾ KATEGORIENENTWICKLUNG ABGESCHLOSSEN")
        print(f"{'='*60}")
        
        # Grundstatistiken
        initial_count = len(initial_categories) if initial_categories else 0
        final_count = len(final_categories)
        new_categories = final_count - initial_count
        
        print(f"â„¹ï¸ Kategorien-Bilanz:")
        print(f"   - Initial: {initial_count}")
        print(f"   - Neu entwickelt: {new_categories}")
        print(f"   - Final: {final_count}")
        
        # SÃ¤ttigungshistorie
        if self.theoretical_saturation_history:
            final_saturation = self.theoretical_saturation_history[-1]
            print(f"\nðŸŽ¯ Finale SÃ¤ttigung:")
            print(f"   - Theoretische SÃ¤ttigung: {final_saturation['theoretical_saturation']:.1%}")
            print(f"   - KategorienqualitÃ¤t: {final_saturation['category_quality']:.1%}")
            print(f"   - Di: {final_saturation['category_diversity']:.1%}")
        
        # Entwicklungsphasen
        if self.category_development_phases:
            print(f"\nðŸ§¾ Entwicklungsphasen:")
            for phase in self.category_development_phases:
                print(f"   Batch {phase['batch']}: +{phase['new_categories']} -> {phase['total_categories']} total")

    
    
    def _format_existing_categories(self, categories: Dict[str, CategoryDefinition]) -> str:
        """Formatiert bestehende Kategorien fuer Prompt"""
        if not categories:
            return "Keine bestehenden Kategorien."
        
        formatted = []
        for name, cat in categories.items():
            formatted.append(f"- {name}: {cat.definition[:100]}...")
        
        return "\n".join(formatted)

    
    async def _enhance_category_definition(self, category: CategoryDefinition) -> Optional[CategoryDefinition]:
        """Verbessert Kategoriendefinition"""
        try:
            prompt = self.prompt_handler._get_definition_enhancement_prompt({
                'name': category.name,
                'definition': category.definition,
                'examples': category.examples
            })
            
            response = await self.llm_provider.create_completion(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "Du bist ein Experte fuer qualitative Inhaltsanalyse."},
                    {"role": "user", "content": prompt}
                ],
                temperature=self.temperature
            )
            
            enhanced_def = response.choices[0].message.content.strip()
            
            if len(enhanced_def.split()) >= 20:
                return category.replace(definition=enhanced_def)
            
        except Exception as e:
            print(f"Fehler bei Definition-Verbesserung: {str(e)}")
        
        return None
    
    async def analyze_grounded_batch(self, segments: List[str], material_percentage: float) -> Dict[str, Any]:
        """
        Analysiert einen Batch von Segmenten im 'grounded' Modus.
        Extrahiert Subcodes und Keywords ohne direkte Zuordnung zu Hauptkategorien.
        Sorgt fuer angemessenen Abstand zwischen Keywords und Subcodes.
        
        Args:
            segments: Liste der Textsegmente
            material_percentage: Prozentsatz des verarbeiteten Materials
            
        Returns:
            Dict[str, Any]: Analyseergebnisse mit Subcodes und Keywords
        """
        try:
            # Cache-Key erstellen
            cache_key = (
                tuple(segments),
                'grounded'
            )
            
            # PrÃ¼fe Cache
            if cache_key in self.analysis_cache:
                print("Nutze gecachte Analyse")
                return self.analysis_cache[cache_key]

            # Bestehende Subcodes sammeln
            existing_subcodes = []
            if hasattr(self, 'collected_subcodes'):
                existing_subcodes = [sc.get('name', '') for sc in self.collected_subcodes if isinstance(sc, dict)]
            
            # Definiere JSON-Schema fuer den grounded Modus
            json_schema = '''{
                "segment_analyses": [
                    {
                        "segment_text": "Textsegment",
                        "subcodes": [
                            {
                                "name": "Subcode-Name",
                                "definition": "Definition des Subcodes",
                                "evidence": ["Textbelege"],
                                "keywords": ["SchlÃœsselwÃ–rter des Subcodes"],
                                "confidence": 0.0-1.0
                            }
                        ],
                        "memo": "Analytische Notizen zum Segment"
                    }
                ],
                "abstraction_quality": {
                    "keyword_subcode_distinction": 0.0-1.0,
                    "comment": "Bewertung der Abstraktionshierarchie"
                },
                "saturation_metrics": {
                    "new_aspects_found": true/false,
                    "coverage": 0.0-1.0,
                    "justification": "BegrÃœndung"
                }
            }'''

            # Verbesserter Prompt mit Fokus auf die Abstraktionshierarchie
            prompt = self.prompt_handler.get_grounded_analysis_prompt(
                segments=segments,
                existing_subcodes=existing_subcodes,
                json_schema=json_schema
            )
            
            token_counter.start_request()

            # API-Call
            response = await self.llm_provider.create_completion(
                    model=self.model_name,
                    messages=[
                        {"role": "system", "content": "Du bist ein Experte fuer qualitative Inhaltsanalyse. Du antwortest auf deutsch."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=self.temperature,
                    response_format={"type": "json_object"}
                )
                
            # Verarbeite Response mit Wrapper
            llm_response = LLMResponse(response)
            result = json.loads(llm_response.extract_json())
            
            
            token_counter.track_response(response, self.model_name)

            # Cache das Ergebnis
            self.analysis_cache[cache_key] = result
            
            # Bewertung der AbstraktionsqualitÃ„t
            abstraction_quality = result.get('abstraction_quality', {})
            if abstraction_quality and 'keyword_subcode_distinction' in abstraction_quality:
                quality_score = abstraction_quality['keyword_subcode_distinction']
                quality_comment = abstraction_quality.get('comment', '')
                print(f"\nAbstraktionsqualitÃ„t: {quality_score:.2f}/1.0")
                print(f"Kommentar: {quality_comment}")
            
            # Debug-Ausgabe und verbesserte Fortschrittsanzeige
            segment_count = len(result.get('segment_analyses', []))
            
            # ZÃ„hle Subcodes und ihre Keywords
            subcode_count = 0
            keyword_count = 0
            new_subcodes = []
            
            for analysis in result.get('segment_analyses', []):
                subcodes = analysis.get('subcodes', [])
                subcode_count += len(subcodes)
                
                for subcode in subcodes:
                    new_subcodes.append(subcode)
                    keyword_count += len(subcode.get('keywords', []))
                    
                    # Zeige Abstraktionsbeispiele fuer besseres Monitoring
                    keywords = subcode.get('keywords', [])
                    if keywords and len(keywords) > 0:
                        print(f"\nAbstraktionsbeispiel:")
                        print(f"Keywords: {', '.join(keywords[:3])}" + ("..." if len(keywords) > 3 else ""))
                        print(f"Subcode: {subcode.get('name', '')}")
            
            # Erweiterte Fortschrittsanzeige
            print(f"\nGrounded Analyse fuer {segment_count} Segmente abgeschlossen:")
            print(f"- {subcode_count} neue Subcodes identifiziert")
            print(f"- {keyword_count} Keywords mit Subcodes verknÃœpft")
            print(f"- Material-Fortschritt: {material_percentage:.1f}%")
            
            # Progress Bar fuer Gesamtfortschritt der Subcode-Sammlung
            if hasattr(self, 'collected_subcodes'):
                total_collected = len(self.collected_subcodes) + subcode_count
                # Einfache ASCII Progress Bar
                bar_length = 30
                filled_length = int(bar_length * material_percentage / 100)
                bar ='=' * filled_length + '=   ' * (bar_length - filled_length)
                
                print(f"\nGesamtfortschritt Grounded-Analyse:")
                print(f"[{bar}] {material_percentage:.1f}%")
                print(f"Bisher gesammelt: {total_collected} Subcodes mit ihren Keywords")
            
            return result
            
        except Exception as e:
            print(f"Fehler bei Grounded-Analyse: {str(e)}")
            print("Details:")
            traceback.print_exc()
            return {}
    
    async def _prefilter_segments(self, segments: List[str]) -> List[str]:
        """
        Filtert Segmente nach Relevanz fuer Kategorienentwicklung.
        Optimiert durch Parallelverarbeitung und Caching.
        """
        async def check_segment(segment: str) -> Tuple[str, float]:
            cache_key = hash(segment)
            if cache_key in self.category_cache:
                return segment, self.category_cache[cache_key]
            
            relevance = await self._assess_segment_relevance(segment)
            self.category_cache[cache_key] = relevance
            return segment, relevance
        
        # Parallele RelevanzprÃ¼fung
        tasks = [check_segment(seg) for seg in segments]
        results = await asyncio.gather(*tasks)
        
        # Filter relevante Segmente
        return [seg for seg, relevance in results if relevance > self.MIN_CONFIDENCE]

    async def _assess_segment_relevance(self, segment: str) -> float:
        """
        Bewertet die Relevanz eines Segments fuer die Kategorienentwicklung.
        """
        prompt = self.prompt_handler.get_segment_relevance_assessment_prompt(segment)
                
        try:
            token_counter.start_request()

            response = await self.llm_provider.create_completion(
                    model=self.model_name,
                    messages=[
                        {"role": "system", "content": "Du bist ein Experte fuer qualitative Inhaltsanalyse. Du antwortest auf deutsch."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=self.temperature,
                    response_format={"type": "json_object"}
                )
                
            # Verarbeite Response mit Wrapper
            llm_response = LLMResponse(response)
            result = json.loads(llm_response.extract_json())

            
            token_counter.track_response(response, self.model_name)

            return float(result.get('relevance_score', 0))
            
        except Exception as e:
            print(f"Error in relevance assessment: {str(e)}")
            return 0.0
    
    def _create_batches(self, segments: List[str], batch_size: int = None) -> List[List[str]]:
        """
        Creates batches of segments for processing.
        
        Args:
            segments: List of text segments to process
            batch_size: Optional custom batch size (defaults to self.BATCH_SIZE)
            
        Returns:
            List[List[str]]: List of segment batches
        """
        batch_size = self.BATCH_SIZE
            
        return [
            segments[i:i + batch_size] 
            for i in range(0, len(segments), batch_size)
        ]
    
    async def _generate_main_categories_from_subcodes(self, initial_categories: Dict[str, CategoryDefinition] = None) -> Dict[str, CategoryDefinition]:
        """
        Generiert Hauptkategorien aus den gesammelten Subcodes - VOLLSTÃ„NDIGE GROUNDED THEORY IMPLEMENTIERUNG
        """
        try:
            # Hole gesammelte Subcodes (mehrere Quellen probieren)
            collected_subcodes = []
            
            if hasattr(self, 'collected_subcodes') and self.collected_subcodes:
                collected_subcodes = self.collected_subcodes
                print(f"ðŸ§¾ Verwende Subcodes aus InductiveCoder: {len(collected_subcodes)}")
            elif hasattr(self, 'analysis_manager') and hasattr(self.analysis_manager, 'collected_subcodes'):
                collected_subcodes = self.analysis_manager.collected_subcodes
                print(f"ðŸ§¾ Verwende Subcodes aus AnalysisManager: {len(collected_subcodes)}")
            else:
                print("âŒ Keine gesammelten Subcodes gefunden - prÃœfe verfÃ¼gbare Attribute:")
                for attr in dir(self):
                    if 'subcode' in attr.lower():
                        print(f"   - {attr}: {getattr(self, attr, 'N/A')}")
                return initial_categories or {}
            
            if len(collected_subcodes) < 5:
                print(f"âŒ Zu wenige Subcodes fuer Hauptkategorien-Generierung: {len(collected_subcodes)} < 5")
                return initial_categories or {}
            
            print(f"\nðŸ•µï¸ GROUNDED THEORY: Generiere Hauptkategorien aus {len(collected_subcodes)} Subcodes")
            
            # Bereite Subcodes fuer LLM-Analyse vor
            subcodes_data = []
            all_keywords = []
            
            for subcode in collected_subcodes:
                subcode_entry = {
                    'name': subcode.get('name', ''),
                    'definition': subcode.get('definition', ''),
                    'keywords': subcode.get('keywords', []),
                    'evidence': subcode.get('evidence', []),
                    'confidence': subcode.get('confidence', 0.7)
                }
                subcodes_data.append(subcode_entry)
                all_keywords.extend(subcode.get('keywords', []))
            
            # Zeige Statistiken
            keyword_counter = Counter(all_keywords)
            top_keywords = keyword_counter.most_common(15)
            avg_confidence = sum(s.get('confidence', 0) for s in collected_subcodes) / len(collected_subcodes)
            
            print(f"\nðŸ§¾ Subcode-Analyse vor Hauptkategorien-Generierung:")
            print(f"   - Subcodes: {len(subcodes_data)}")
            print(f"   - Einzigartige Keywords: {len(set(all_keywords))}")
            print(f"   - Durchschnittliche Konfidenz: {avg_confidence:.2f}")
            print(f"   - Top Keywords: {', '.join([f'{kw}({count})' for kw, count in top_keywords[:8]])}")
            
            # Erstelle optimierten Prompt fuer Grounded Theory
            enhanced_prompt = self.prompt_handler.get_main_categories_generation_prompt(
                subcodes_data=subcodes_data,
                top_keywords=top_keywords,
                avg_confidence=avg_confidence
            )
                        
            # LLM-Aufruf
            print("\nâ„¹ï¸ Generiere Hauptkategorien via Grounded Theory Analyse...")
            
            token_counter.start_request()

            response = await self.llm_provider.create_completion(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "Du bist ein Experte fuer Grounded Theory und qualitative Inhaltsanalyse. Du antwortest auf deutsch."},
                    {"role": "user", "content": enhanced_prompt}
                ],
                temperature=self.temperature,
                response_format={"type": "json_object"}
            )
            
            llm_response = LLMResponse(response)
            result = json.loads(llm_response.extract_json())
            
            
            token_counter.track_response(response, self.model_name)
            
            # Verarbeite Ergebnisse zu CategoryDefinition-Objekten
            grounded_categories = {}
            subcode_mapping = result.get('subcode_mappings', {})
            
            print(f"\nâœ… Hauptkategorien-Generierung abgeschlossen:")
            
            for i, category_data in enumerate(result.get('main_categories', []), 1):
                name = category_data.get('name', '')
                definition = category_data.get('definition', '')
                
                if name and definition:
                    # Erstelle Subcategories aus zugeordneten Subcodes
                    subcategories = {}
                    assigned_subcodes = []
                    
                    for subcode_data in category_data.get('subcodes', []):
                        subcode_name = subcode_data.get('name', '')
                        subcode_definition = subcode_data.get('definition', '')
                        if subcode_name and subcode_definition:
                            subcategories[subcode_name] = subcode_definition
                            assigned_subcodes.append(subcode_name)
                    
                    # Erstelle CategoryDefinition
                    grounded_categories[name] = CategoryDefinition(
                        name=name,
                        definition=definition,
                        examples=category_data.get('examples', []),
                        rules=category_data.get('rules', []),
                        subcategories=subcategories,
                        added_date=datetime.now().strftime("%Y-%m-%d"),
                        modified_date=datetime.now().strftime("%Y-%m-%d")
                    )
                    
                    # Zeige Details
                    characteristic_keywords = ', '.join(category_data.get('characteristic_keywords', [])[:5])
                    print(f"   {i}. ðŸ”€ '{name}': {len(subcategories)} Subcodes zugeordnet")
                    print(f"      Keywords: {characteristic_keywords}")
                    print(f"      Subcodes: {', '.join(assigned_subcodes[:3])}{'...' if len(assigned_subcodes) > 3 else ''}")
            
            # Meta-Analyse Ergebnisse
            meta = result.get('meta_analysis', {})
            if meta:
                print(f"\nâ„¹ï¸ Grounded Theory Meta-Analyse:")
                print(f"   - Verarbeitete Subcodes: {meta.get('total_subcodes_processed', len(subcodes_data))}")
                print(f"   - Generierte Hauptkategorien: {len(grounded_categories)}")
                print(f"   - Theoretische SÃ¤ttigung: {meta.get('theoretical_saturation', 0):.2f}")
                print(f"   - Subcode-Abdeckung: {meta.get('coverage', 0):.2f}")
            
            # PrÃ¼fe Subcode-Zuordnung
            mapped_subcodes = set(subcode_mapping.values()) if subcode_mapping else set()
            all_subcode_names = set(s['name'] for s in subcodes_data)
            unmapped_subcodes = all_subcode_names - mapped_subcodes
            
            if unmapped_subcodes:
                print(f"\nâŒ {len(unmapped_subcodes)} Subcodes wurden nicht zugeordnet:")
                for subcode in list(unmapped_subcodes)[:5]:
                    print(f"   - {subcode}")
                if len(unmapped_subcodes) > 5:
                    print(f"   ... und {len(unmapped_subcodes) - 5} weitere")
            else:
                print(f"\nâœ… Alle {len(all_subcode_names)} Subcodes erfolgreich zugeordnet")
            
            # Kombiniere mit initial categories falls vorhanden
            if initial_categories:
                combined_categories = initial_categories.copy()
                for name, category in grounded_categories.items():
                    combined_categories[name] = category
                print(f"\nÃ°Å¸â€â€” Kombiniert mit {len(initial_categories)} initialen Kategorien")
                return combined_categories
            
            return grounded_categories
            
        except Exception as e:
            print(f"âš ï¸ Fehler bei Grounded Theory Hauptkategorien-Generierung: {str(e)}")
            import traceback
            traceback.print_exc()
            return initial_categories or {}
        
    def _create_category_definition(self, cat_data: dict) -> CategoryDefinition:
        """
        Erstellt CategoryDefinition aus API-Response Dictionary
        GRUND: Wird fuer Kategorienentwicklung benÃ–tigt
        """
        try:
            return CategoryDefinition(
                name=cat_data.get('name', ''),
                definition=cat_data.get('definition', ''),
                examples=cat_data.get('evidence', []),
                rules=[],  # Wird spaeter entwickelt
                subcategories={
                    sub.get('name', ''): sub.get('definition', '')
                    for sub in cat_data.get('subcategories', [])
                },
                added_date=datetime.now().strftime("%Y-%m-%d"),
                modified_date=datetime.now().strftime("%Y-%m-%d")
            )
        except Exception as e:
            print(f"Fehler bei CategoryDefinition-Erstellung: {str(e)}")
            return None

    def _calculate_text_similarity(self, text1: str, text2: str) -> float:
        """Berechnet die Ã„hnlichkeit zwischen zwei Texten mit Caching."""
        cache_key = f"{hash(text1)}_{hash(text2)}"
        
        if cache_key in self.similarity_cache:
            return self.similarity_cache[cache_key]
            
        # Konvertiere Texte zu Sets von WÃ–rtern
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        # Berechne Jaccard-Ã„hnlichkeit
        intersection = len(words1.intersection(words2))
        union = len(words1.union(words2))
        
        similarity = intersection / union if union > 0 else 0.0
        
        # Cache das Ergebnis
        self.similarity_cache[cache_key] = similarity
        
        return similarity

    def _find_similar_category(self, category: CategoryDefinition, existing_categories: Dict[str, CategoryDefinition]) -> Optional[str]:
        """
        Findet Ã„hnliche Kategorie basierend auf Ã„hnlichkeitsschwelle
        """
        for existing_name, existing_cat in existing_categories.items():
            similarity = self._calculate_category_similarity(category, existing_cat)
            
            if similarity > self.similarity_threshold:
                print(f"ðŸ•µï¸ Ã„hnliche Kategorie gefunden: '{category.name}' Ã¢â€ â€ '{existing_name}' ({similarity:.2f})")
                return existing_name
        
        return None

    def _extract_base_segment_id(self, coding: Dict) -> str:
        """
        Extrahiert die Basis-Segment-ID fuer ReliabilitÃ¤tsberechnung.
        Behandelt Mehrfachkodierung korrekt.
        
        Args:
            coding: Kodierung mit segment_id
            
        Returns:
            str: Basis-Segment-ID ohne Mehrfachkodierungs-Suffixe
        """
        segment_id = coding.get('segment_id', '')
        
        # Entferne Mehrfachkodierungs-Suffixe
        # Format kann sein: "doc_chunk_5" oder "doc_chunk_5-1" fuer Mehrfachkodierung
        if '-' in segment_id:
            # PrÃ¼fe ob es ein Mehrfachkodierungs-Suffix ist (endet mit -Zahl)
            parts = segment_id.rsplit('-', 1)
            if len(parts) == 2 and parts[1].isdigit():
                base_id = parts[0]
            else:
                base_id = segment_id
        else:
            base_id = segment_id
        
        return base_id
    
    def _document_reliability_results(
        self, 
        alpha: float, 
        total_segments: int, 
        total_coders: int, 
        category_frequencies: dict
    ) -> str:
        """
        Generiert einen detaillierten Bericht Ãœber die Intercoder-ReliabilitÃ¤t.

        Args:
            alpha: Krippendorffs Alpha Koeffizient
            total_segments: Gesamtzahl der analysierten Segmente
            total_coders: Gesamtzahl der Kodierer
            category_frequencies: HÃ„ufigkeiten der Kategorien
            
        Returns:
            str: Formatierter Bericht als Markdown-Text
        """
        try:
            # Bestimme das ReliabilitÃ¤tsniveau basierend auf Alpha
            reliability_level = (
                "Excellent" if alpha > 0.8 else
                "Acceptable" if alpha > 0.667 else
                "Poor"
            )
            
            # Erstelle den Bericht
            report = [
                "# Intercoder Reliability Analysis Report",
                f"\n## Overview",
                f"- Number of text segments: {total_segments}",
                f"- Number of coders: {total_coders}",
                f"- Krippendorff's Alpha: {alpha:.3f}",
                f"- Reliability Assessment: {reliability_level}",
                "\n## Category Usage",
                "| Category | Frequency |",
                "|----------|-----------|"
            ]
            
            # FÃ¼ge KategorienhÃ„ufigkeiten hinzu
            for category, frequency in sorted(category_frequencies.items(), key=lambda x: x[1], reverse=True):
                report.append(f"| {category} | {frequency} |")
            
            # FÃ¼ge Empfehlungen hinzu
            report.extend([
                "\n## Recommendations",
                "Based on the reliability analysis, the following actions are suggested:"
            ])
            
            if alpha < 0.667:
                report.extend([
                    "1. Review and clarify category definitions",
                    "2. Provide additional coder training",
                    "3. Consider merging similar categories",
                    "4. Add more explicit coding rules"
                ])
            elif alpha < 0.8:
                report.extend([
                    "1. Review cases of disagreement",
                    "2. Refine coding guidelines for ambiguous cases",
                    "3. Consider additional coder calibration"
                ])
            else:
                report.extend([
                    "1. Continue with current coding approach",
                    "2. Document successful coding practices",
                    "3. Consider using this category system as a template for future analyses"
                ])
            
            # FÃ¼ge detaillierte Analyse hinzu
            report.extend([
                "\n## Detailed Analysis",
                "### Interpretation of Krippendorff's Alpha",
                "- > 0.800: Excellent reliability",
                "- 0.667 - 0.800: Acceptable reliability",
                "- < 0.667: Poor reliability",
                "\n### Category Usage Analysis",
                "- Most frequently used category: " + max(category_frequencies.items(), key=lambda x: x[1])[0],
                "- Least frequently used category: " + min(category_frequencies.items(), key=lambda x: x[1])[0],
                "- Number of categories with single use: " + str(sum(1 for x in category_frequencies.values() if x == 1)),
                "\n### Coder Performance",
                "- Average segments per coder: " + f"{total_segments/total_coders:.1f}" if total_coders > 0 else "N/A"
            ])
            
            # FÃ¼ge Zeitstempel hinzu
            report.append(f"\nReport generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            
            return '\n'.join(report)
            
        except Exception as e:
            print(f"Error generating reliability report: {str(e)}")
            import traceback
            traceback.print_exc()
            return "# Reliability Report\n\nError generating report"
    
  
    async def _meets_quality_standards(self, category: CategoryDefinition) -> bool:
        """
        PrÃœft ob Kategorie strikte QualitÃ„tsstandards erfÃœllt
        VEREINFACHT fuer bessere DurchlÃ„ssigkeit
        """
        # SicherheitsprÃ¼fung: Category muss gÃ¼ltig sein
        if category is None or not hasattr(category, 'definition'):
            print(f"âš ï¸ UngÃ¼ltige CategoryDefinition")
            return False
        
        # SicherheitsprÃ¼fung: Definition muss gesetzt sein
        if not category.definition or not isinstance(category.definition, str):
            print(f"âš ï¸ '{category.name}': Definition fehlt oder ungÃ¼ltig")
            return False
        
        # 1. Definition ausreichend lang (weiter reduziert)
        if len(category.definition.split()) < 5:  # reduziert von 10
            print(f"âš ï¸ '{category.name}': Definition zu kurz ({len(category.definition.split())} WÃ¶rter)")
            return False
        
        # 2. GenÃ¼gend Beispiele (weiter reduziert) 
        if not category.examples or len(category.examples) < 1:  # reduziert von 2
            print(f"âš ï¸ '{category.name}': Zu wenige Beispiele ({len(category.examples) if category.examples else 0})")
            return False
        
        # 3. Name nicht zu kurz
        if not category.name or len(category.name) < 3:
            print(f"âš ï¸ Name zu kurz oder leer")
            return False
        
        print(f"âœ… '{category.name}': QualitÃ¤tsstandards erfÃ¼llt")
        return True

    async def _auto_merge_categories(self, cat1: CategoryDefinition, cat2: CategoryDefinition, name1: str, name2: str) -> Optional[CategoryDefinition]:
        """
        Automatische intelligente ZusammenfÃœhrung Ã„hnlicher Kategorien
        """
        print(f"Ã°Å¸â€â€” Automatische ZusammenfÃœhrung: '{name1}' + '{name2}'")
        
        try:
            # WÃ„hle besseren Namen
            better_name = self._choose_better_name(name1, name2)
            
            # Kombiniere Definitionen intelligent
            combined_definition = await self._merge_definitions_intelligent(cat1.definition, cat2.definition)
            
            # Kombiniere Beispiele (entferne Duplikate)
            combined_examples = list(set(cat1.examples + cat2.examples))
            
            # Kombiniere Regeln
            combined_rules = list(set(cat1.rules + cat2.rules))
            
            # Kombiniere Subkategorien
            combined_subcats = {**cat1.subcategories, **cat2.subcategories}
            
            # Erstelle zusammengefÃœhrte Kategorie
            merged = CategoryDefinition(
                name=better_name,
                definition=combined_definition,
                examples=combined_examples,
                rules=combined_rules,
                subcategories=combined_subcats,
                added_date=min(cat1.added_date, cat2.added_date),
                modified_date=datetime.now().strftime("%Y-%m-%d")
            )
            
            print(f"âœ… ZusammenfÃœhrung erfolgreich zu '{better_name}'")
            return merged
            
        except Exception as e:
            print(f"âš ï¸ Fehler bei automatischer ZusammenfÃœhrung: {str(e)}")
            return None

    async def _merge_definitions_intelligent(self, def1: str, def2: str) -> str:
        """
        Intelligente ZusammenfÃœhrung von Definitionen via LLM
        """
        prompt = self.prompt_handler.get_definition_enhancement_prompt({
            'definition1': def1,
            'definition2': def2
        })
                
        try:
            response = await self.llm_provider.create_completion(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "Du bist ein Experte fuer qualitative Inhaltsanalyse."},
                    {"role": "user", "content": prompt}
                ],
                temperature=self.temperature
            )
            
            merged_def = response.choices[0].message.content.strip()
            
            # Fallback falls LLM-Merge fehlschlÃ„gt
            if len(merged_def.split()) < 15:
                return f"{def1} ZusÃ¤tzlich umfasst dies: {def2}"
            
            return merged_def
            
        except Exception as e:
            print(f"Fehler bei Definition-Merge: {str(e)}")
            return f"{def1} Erweitert um: {def2}"

    def _calculate_category_similarity(self, cat1: CategoryDefinition, cat2: CategoryDefinition) -> float:
        """
        Berechnet Ã„hnlichkeit zwischen zwei Kategorien basierend auf mehreren Faktoren
        """
        # 1. Name-Ã„hnlichkeit (30%)
        name_similarity = self._calculate_text_similarity(cat1.name.lower(), cat2.name.lower()) * 0.3
        
        # 2. Definition-Ã„hnlichkeit (50%)
        def_similarity = self._calculate_text_similarity(cat1.definition, cat2.definition) * 0.5
        
        # 3. Subkategorien-Ãœberlappung (20%)
        subcats1 = set(cat1.subcategories.keys())
        subcats2 = set(cat2.subcategories.keys())
        
        if subcats1 and subcats2:
            subcat_overlap = len(subcats1 & subcats2) / len(subcats1 | subcats2)
        else:
            subcat_overlap = 0
        
        subcat_similarity = subcat_overlap * 0.2
        
        total_similarity = name_similarity + def_similarity + subcat_similarity
        
        return min(total_similarity, 1.0)

    async def _merge_categories_intelligent(self, cat1: CategoryDefinition, cat2: CategoryDefinition, name1: str, name2: str) -> Optional[CategoryDefinition]:
        """
        Intelligente ZusammenfÃœhrung mit QualitÃ„tsprÃœfung
        """
        # Verwende die bereits implementierte _auto_merge_categories
        merged = await self._auto_merge_categories(cat1, cat2, name1, name2)
        
        if merged and await self._meets_quality_standards(merged):
            return merged
        
        print(f"âš ï¸ ZusammengefÃœhrte Kategorie erfÃœllt QualitÃ„tsstandards nicht")
        return None

    def _choose_better_name(self, name1: str, name2: str) -> str:
        """
        WÃ„hlt den besseren Kategorienamen basierend auf Kriterien
        """
        # Kriterien fuer besseren Namen
        score1 = score2 = 0
        
        # 1. LÃ„nge (nicht zu kurz, nicht zu lang)
        if 5 <= len(name1) <= 25:
            score1 += 1
        if 5 <= len(name2) <= 25:
            score2 += 1
        
        # 2. Keine Sonderzeichen/Zahlen
        if name1.replace('_', '').replace('-', '').isalpha():
            score1 += 1
        if name2.replace('_', '').replace('-', '').isalpha():
            score2 += 1
        
        # 3. Keine englischen WÃ–rter
        english_words = {'research', 'development', 'management', 'system', 'process', 'analysis'}
        if not any(word.lower() in english_words for word in name1.split('_')):
            score1 += 1
        if not any(word.lower() in english_words for word in name2.split('_')):
            score2 += 1
        
        # 4. KÃœrzerer Name bei Gleichstand
        if score1 == score2:
            return name1 if len(name1) <= len(name2) else name2
        
        return name1 if score1 > score2 else name2

    def _update_usage_history(self, category_names: List[str]) -> None:
        """
        Aktualisiert die Nutzungshistorie fuer Kategorien
        """
        for name in category_names:
            if name in self.category_usage_history:
                self.category_usage_history[name] += 1
            else:
                self.category_usage_history[name] = 1
        
        print(f"ðŸ§¾ Nutzungshistorie aktualisiert fuer: {category_names}")
        print(f"    Aktuelle Nutzung: {dict(list(self.category_usage_history.items())[-3:])}")
    
    def _log_performance(self, 
                        num_segments: int,
                        num_categories: int,
                        processing_time: float) -> None:
        """
        Protokolliert Performance-Metriken.
        """
        metrics = {
            'timestamp': datetime.now().isoformat(),
            'segments_processed': num_segments,
            'categories_developed': num_categories,
            'processing_time': processing_time,
            'segments_per_second': num_segments / processing_time
        }
        
        print("\nPerformance Metrics:")
        print(f"- Segments processed: {num_segments}")
        print(f"- Categories developed: {num_categories}")
        print(f"- Processing time: {processing_time:.2f}s")
        print(f"- Segments/second: {metrics['segments_per_second']:.2f}")
        
        # Speichere Metriken
        self.batch_results.append(metrics)
    def _find_similar_category(self, category: CategoryDefinition, existing_categories: Dict[str, CategoryDefinition]) -> Optional[str]:
        """
        Findet Ã„hnliche existierende Kategorien basierend auf Namen und Definition.
        """
        try:
            best_match = None
            highest_similarity = 0.0
            
            for existing_name, existing_cat in existing_categories.items():
                # Berechne Ã„hnlichkeit basierend auf verschiedenen Faktoren
                
                # 1. Name-Ã„hnlichkeit (gewichtet: 0.3)
                name_similarity = self._calculate_text_similarity(
                    category.name.lower(),
                    existing_name.lower()
                ) * 0.3
                
                # 2. Definitions-Ã„hnlichkeit (gewichtet: 0.5)
                definition_similarity = self._calculate_text_similarity(
                    category.definition,
                    existing_cat.definition
                ) * 0.5
                
                # 3. Subkategorien-Ãœberlappung (gewichtet: 0.2)
                subcats1 = set(category.subcategories.keys())
                subcats2 = set(existing_cat.subcategories.keys())
                if subcats1 and subcats2:
                    subcat_overlap = len(subcats1 & subcats2) / len(subcats1 | subcats2)
                else:
                    subcat_overlap = 0
                subcat_similarity = subcat_overlap * 0.2
                
                # GesamtÃ„hnlichkeit
                total_similarity = name_similarity + definition_similarity + subcat_similarity
                
                # Update beste Ãœbereinstimmung
                if total_similarity > highest_similarity:
                    highest_similarity = total_similarity
                    best_match = existing_name
            
            # Nur zurÃœckgeben wenn Ã„hnlichkeit hoch genug
            if highest_similarity > 0.7:  # Schwellenwert fuer Ã„hnlichkeit
                print(f"\nÃ¢Å¡Â  Hohe Ã„hnlichkeit ({highest_similarity:.2f}) gefunden:")
                print(f"- Neue Kategorie: {category.name}")
                print(f"- Existierende Kategorie: {best_match}")
                return best_match
                
            return None
            
        except Exception as e:
            print(f"Fehler bei Ã„hnlichkeitsprÃœfung: {str(e)}")
            return None


# --- Klasse: ManualCoder ---
